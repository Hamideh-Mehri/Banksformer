{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from prepare_data import preprocess_data_czech\n",
    "from field_info import FieldInfo\n",
    "from tensor_encoder import TensorEncoder\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('../DATA/tr_by_acct_w_age.csv')\n",
    "data, LOG_AMOUNT_SCALE, TD_SCALE, START_DATE, TCODE_TO_NUM, NUM_TO_TCODE = preprocess_data_czech(raw_data)\n",
    "data2 = data[['account_id','age','tcode', 'tcode_num', 'datetime', 'month', 'dow', 'day', 'dtme' ,'log_amount_sc','td_sc']]\n",
    "df= data2.copy()\n",
    "\n",
    "n_tcodes = len(TCODE_TO_NUM)\n",
    "\n",
    "info = FieldInfo(n_tcodes)\n",
    "\n",
    "max_seq_len = 80\n",
    "min_seq_len = 20\n",
    "encoder = TensorEncoder(df, info, max_seq_len, min_seq_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from field_info import FieldInfo\n",
    "ACTIVATIONS = {\n",
    "    \"td_sc\": \"relu\",\n",
    "    \"log_amount_sc\": \"relu\"\n",
    "}\n",
    "fieldInfo = FieldInfo(n_tcodes)\n",
    "config = {}\n",
    "config[\"ORDER\"] = fieldInfo.DATA_KEY_ORDER\n",
    "config[\"FIELD_STARTS_IN\"] = fieldInfo.FIELD_STARTS_IN\n",
    "config[\"FIELD_DIMS_IN\"] = fieldInfo.FIELD_DIMS_IN\n",
    "config[\"FIELD_STARTS_NET\"] = fieldInfo.FIELD_STARTS_NET\n",
    "config[\"FIELD_DIMS_NET\"] = fieldInfo.FIELD_DIMS_NET\n",
    "config[\"ACTIVATIONS\"] = ACTIVATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tcode_num': 16,\n",
       " 'dow': 2,\n",
       " 'month': 2,\n",
       " 'day': 2,\n",
       " 'dtme': 2,\n",
       " 'td_sc': 1,\n",
       " 'log_amount_sc': 1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fieldInfo.FIELD_DIMS_IN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99101, 72764, 14354)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.count_variable_length_seqs_with_overlap(), encoder.count_seqs_with_overlap(), encoder.count_seqs_in_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 10:04:38.205908: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-12-01 10:04:38.207253: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2023-12-01 10:04:38.237707: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:3b:00.0 name: Quadro RTX 8000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.45GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2023-12-01 10:04:38.237880: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:af:00.0 name: Quadro RTX 8000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.45GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2023-12-01 10:04:38.237897: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-12-01 10:04:38.259569: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-12-01 10:04:38.259670: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-12-01 10:04:38.272878: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-12-01 10:04:38.275931: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-12-01 10:04:38.299037: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-12-01 10:04:38.302565: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-12-01 10:04:38.343859: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-12-01 10:04:38.344862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\n",
      "2023-12-01 10:04:38.346078: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-01 10:04:38.347888: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-12-01 10:04:38.566008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:3b:00.0 name: Quadro RTX 8000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.45GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2023-12-01 10:04:38.566194: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:af:00.0 name: Quadro RTX 8000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.45GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2023-12-01 10:04:38.566229: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-12-01 10:04:38.566252: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-12-01 10:04:38.566259: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-12-01 10:04:38.566266: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-12-01 10:04:38.566272: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-12-01 10:04:38.566279: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-12-01 10:04:38.566286: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-12-01 10:04:38.566292: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-12-01 10:04:38.566763: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\n",
      "2023-12-01 10:04:38.569553: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-12-01 10:04:40.338180: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-12-01 10:04:40.338214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 \n",
      "2023-12-01 10:04:40.338218: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N Y \n",
      "2023-12-01 10:04:40.338220: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   Y N \n",
      "2023-12-01 10:04:40.341901: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 511 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:3b:00.0, compute capability: 7.5)\n",
      "2023-12-01 10:04:40.343399: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 45387 MB memory) -> physical GPU (device: 1, name: Quadro RTX 8000, pci bus id: 0000:af:00.0, compute capability: 7.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished encoding 2000 of 14354 seqs\n",
      "Finished encoding 4000 of 14354 seqs\n",
      "Finished encoding 6000 of 14354 seqs\n",
      "Finished encoding 8000 of 14354 seqs\n",
      "Finished encoding 10000 of 14354 seqs\n",
      "Finished encoding 12000 of 14354 seqs\n",
      "Finished encoding 14000 of 14354 seqs\n",
      "Took 73.28 secs\n"
     ]
    }
   ],
   "source": [
    "encoder.encode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14354, 81, 26)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.inp_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.inp_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TensorFlow dataset from the entire tensors\n",
    "ds_all = tf.data.Dataset.from_tensor_slices((encoder.inp_tensor.astype(np.float32), encoder.tar_tensor.astype(np.float32)))\n",
    "\n",
    "def make_batches(ds, buffer_size, batch_size):\n",
    "    return ds.cache().shuffle(buffer_size).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "BUFFER_SIZE = ds_all.cardinality().numpy()\n",
    "bs = 64  # batch size\n",
    "\n",
    "# Create train batches from the entire dataset\n",
    "train_batches = make_batches(ds_all, BUFFER_SIZE, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((None, 81, 26), (None, 80, 7)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create only one sample of inp and tar to trace one iteration of loop\n",
    "j = 0\n",
    "for (batch_no, (inp, tar)) in enumerate(train_batches):\n",
    "    if j == 0:\n",
    "       break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules import InputEmbedLayer,InputEmbedLayer_Res, ResidualLayer, RandomNoise_Simulator_Normal, positional_encoding, MultiHeadAttention, Transformer, create_masks, DecoderLayer, Decoder\n",
    "import tensorflow as tf\n",
    "features = 26\n",
    "d_embedding = 128\n",
    "dff = 128\n",
    "d_model = 128\n",
    "batch_size = 64\n",
    "seq_len = 80\n",
    "maximum_position_encoding = 256\n",
    "rate = 0.1\n",
    "num_heads = 2\n",
    "num_layers = 4\n",
    "deepmodel = Transformer(features, dff, d_embedding, d_model, maximum_position_encoding,num_heads, num_layers,config, rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method Decoder.call of <modules.Decoder object at 0x7f49df089510>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Decoder.call of <modules.Decoder object at 0x7f49df089510>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method MultiHeadAttention.call of <modules.MultiHeadAttention object at 0x7f49b5b1d550>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method MultiHeadAttention.call of <modules.MultiHeadAttention object at 0x7f49b5b1d550>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "transformer  = deepmodel.make_transformer(tar, inp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer(inp[:, :-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_scce_logit = SparseCategoricalCrossentropy(from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'day': 'scce',\n",
       " 'dtme': 'scce',\n",
       " 'dow': 'scce',\n",
       " 'month': 'scce',\n",
       " 'tcode_num': 'scce',\n",
       " 'td_sc': 'pdf',\n",
       " 'log_amount_sc': 'pdf'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LOSS_TYPES = fieldInfo.LOSS_TYPES\n",
    "LOSS_TYPES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules import InputEmbedLayer,InputEmbedLayer_Res, ResidualLayer, RandomNoise_Simulator_Normal, positional_encoding, MultiHeadAttention, create_masks, DecoderLayer, Decoder\n",
    "import tensorflow as tf\n",
    "features = 26\n",
    "d_embedding = 128\n",
    "dff = 128\n",
    "d_model = 128\n",
    "batch_size = 64\n",
    "seq_len = 80\n",
    "maximum_position_encoding = 256\n",
    "rate = 0.1\n",
    "num_heads = 2\n",
    "num_layers = 4\n",
    "z = RandomNoise_Simulator_Normal(batch_size, seq_len, features)\n",
    "\n",
    "#Transformer Model\n",
    "input_ = tf.keras.layers.Input(shape=(None, features))\n",
    "x = InputEmbedLayer(features, dff , d_embedding)(input_)\n",
    "\n",
    "pos_encoding = positional_encoding(maximum_position_encoding, d_embedding)   #(1, maximum_position_encoding=256, d_model=128)\n",
    "\n",
    "seq_len = tf.shape(x)[1]\n",
    "x += pos_encoding[:, :seq_len, :]     #x is the output of Input layer\n",
    "\n",
    "x = tf.keras.layers.Dropout(rate)(x, training=True)\n",
    "\n",
    "mask, _ = create_masks(tar)\n",
    "d_inp_decoder = tf.keras.backend.int_shape(x)[-1]\n",
    "\n",
    "out, attention_weights = Decoder(num_layers, d_inp_decoder, d_model, num_heads, dff)(x, True, mask)\n",
    "\n",
    "final_output = tf.keras.layers.Dense(d_model, activation=None)(out)\n",
    "model = tf.keras.models.Model(input_, final_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from modules import InputEmbedLayer,InputEmbedLayer_Res, ResidualLayer, RandomNoise_Simulator_Normal, positional_encoding, MultiHeadAttention, create_masks, DecoderLayer\n",
    "# import tensorflow as tf\n",
    "# features = 26\n",
    "# d_embedding = 128\n",
    "# dff = 128\n",
    "# d_model = 128\n",
    "# batch_size = 64\n",
    "# seq_len = 80\n",
    "# maximum_position_encoding = 256\n",
    "# rate = 0.1\n",
    "# num_heads = 2\n",
    "# num_layers = 4\n",
    "# z = RandomNoise_Simulator_Normal(batch_size, seq_len, features)\n",
    "\n",
    "# #Transformer Model\n",
    "# input_ = tf.keras.layers.Input(shape=(None, features))\n",
    "# x = InputEmbedLayer(features, dff , d_embedding)(input_)\n",
    "\n",
    "# pos_encoding = positional_encoding(maximum_position_encoding, d_embedding)   #(1, maximum_position_encoding=256, d_model=128)\n",
    "\n",
    "# seq_len = tf.shape(x)[1]\n",
    "# x += pos_encoding[:, :seq_len, :]     #x is the output of Input layer\n",
    "\n",
    "# x = tf.keras.layers.Dropout(rate)(x, training=True)\n",
    "\n",
    "# attention_weights = {}\n",
    "# mask, _ = create_masks(tar)\n",
    "# for i in range(num_layers):\n",
    "#     d_inp_decoder = tf.keras.backend.int_shape(x)[-1]\n",
    "#     x, attentionweights = DecoderLayer(d_inp_decoder, d_model, num_heads, dff)(x, True, mask)\n",
    "#     attention_weights['decoder_layer{}'.format(i+1)] = attentionweights\n",
    "\n",
    "# final_output = tf.keras.layers.Dense(d_model, activation=None)(x)\n",
    "\n",
    "\n",
    "# model = tf.keras.models.Model(input_, final_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(inp[:, :-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'decoder_layer1': <KerasTensor: shape=(64, 2, 80, 80) dtype=float32 (created by layer 'decoder_3')>,\n",
       " 'decoder_layer2': <KerasTensor: shape=(64, 2, 80, 80) dtype=float32 (created by layer 'decoder_3')>,\n",
       " 'decoder_layer3': <KerasTensor: shape=(64, 2, 80, 80) dtype=float32 (created by layer 'decoder_3')>,\n",
       " 'decoder_layer4': <KerasTensor: shape=(64, 2, 80, 80) dtype=float32 (created by layer 'decoder_3')>}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "FIELD_DIMS_IN, FIELD_STARTS_IN, FIELD_DIMS_TAR, FIELD_STARTS_TAR, FIELD_DIMS_NET, FIELD_STARTS_NET = get_field_info(ds_suffix)\n",
    "\n",
    "config[\"ORDER\"] = DATA_KEY_ORDER\n",
    "config[\"FIELD_STARTS_IN\"] = FIELD_STARTS_IN\n",
    "config[\"FIELD_DIMS_IN\"] = FIELD_DIMS_IN\n",
    "config[\"FIELD_STARTS_NET\"] = FIELD_STARTS_NET\n",
    "config[\"FIELD_DIMS_NET\"] = FIELD_DIMS_NET\n",
    "\n",
    "\n",
    "config[\"ACTIVATIONS\"] = ACTIVATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
