{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-20 09:12:39.251223: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/users/fs2/hmehri/pythonproject/Thesis/synthetic')\n",
    "from lib.prepare_data import preprocess_data_czech\n",
    "from lib.field_info import FieldInfo\n",
    "from lib.tensor_encoder import TensorEncoder\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "pd.set_option('display.max_rows', 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('../DATA/tr_by_acct_w_age.csv')\n",
    "data, LOG_AMOUNT_SCALE, TD_SCALE,ATTR_SCALE, START_DATE, TCODE_TO_NUM, NUM_TO_TCODE = preprocess_data_czech(raw_data)\n",
    "data2 = data[['account_id','age','age_sc', 'tcode', 'tcode_num', 'datetime', 'month', 'dow', 'day','td', 'dtme', 'log_amount','log_amount_sc','td_sc']]\n",
    "df= data2.copy()\n",
    "\n",
    "n_tcodes = len(TCODE_TO_NUM)\n",
    "\n",
    "info = FieldInfo(n_tcodes)\n",
    "\n",
    "max_seq_len = 80\n",
    "min_seq_len = 20\n",
    "df_test = df[:10]\n",
    "encoder = TensorEncoder(df, info, max_seq_len, min_seq_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-20 09:13:22.703049: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-12-20 09:13:22.704284: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2023-12-20 09:13:22.756582: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:3b:00.0 name: Quadro RTX 8000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.45GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2023-12-20 09:13:22.756771: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:af:00.0 name: Quadro RTX 8000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.45GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2023-12-20 09:13:22.756789: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-12-20 09:13:22.758566: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-12-20 09:13:22.758620: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-12-20 09:13:22.760208: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-12-20 09:13:22.760441: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-12-20 09:13:22.761961: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-12-20 09:13:22.762665: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-12-20 09:13:22.765894: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-12-20 09:13:22.766525: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\n",
      "2023-12-20 09:13:22.767082: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-20 09:13:22.768394: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-12-20 09:13:22.918963: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:3b:00.0 name: Quadro RTX 8000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.45GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2023-12-20 09:13:22.919147: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:af:00.0 name: Quadro RTX 8000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.45GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2023-12-20 09:13:22.919177: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-12-20 09:13:22.919194: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-12-20 09:13:22.919201: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-12-20 09:13:22.919208: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-12-20 09:13:22.919214: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-12-20 09:13:22.919221: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-12-20 09:13:22.919228: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-12-20 09:13:22.919234: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-12-20 09:13:22.919731: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\n",
      "2023-12-20 09:13:22.919761: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-12-20 09:13:23.684265: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-12-20 09:13:23.684296: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 \n",
      "2023-12-20 09:13:23.684301: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N Y \n",
      "2023-12-20 09:13:23.684303: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   Y N \n",
      "2023-12-20 09:13:23.685194: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 45387 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:3b:00.0, compute capability: 7.5)\n",
      "2023-12-20 09:13:23.685804: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 45387 MB memory) -> physical GPU (device: 1, name: Quadro RTX 8000, pci bus id: 0000:af:00.0, compute capability: 7.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished encoding 2000 of 14354 seqs\n",
      "Finished encoding 4000 of 14354 seqs\n",
      "Finished encoding 6000 of 14354 seqs\n",
      "Finished encoding 8000 of 14354 seqs\n",
      "Finished encoding 10000 of 14354 seqs\n",
      "Finished encoding 12000 of 14354 seqs\n",
      "Finished encoding 14000 of 14354 seqs\n",
      "Took 35.54 secs\n"
     ]
    }
   ],
   "source": [
    "encoder.encode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'tcode_num': 16,\n",
       "  'dow': 2,\n",
       "  'month': 2,\n",
       "  'day': 2,\n",
       "  'dtme': 2,\n",
       "  'td_sc': 1,\n",
       "  'log_amount_sc': 1},\n",
       " {'tcode_num': 16,\n",
       "  'dow': 7,\n",
       "  'month': 12,\n",
       "  'day': 31,\n",
       "  'dtme': 31,\n",
       "  'td_sc': 2,\n",
       "  'log_amount_sc': 1},\n",
       " {'tcode_num': 1,\n",
       "  'dow': 1,\n",
       "  'month': 1,\n",
       "  'day': 1,\n",
       "  'dtme': 1,\n",
       "  'td_sc': 1,\n",
       "  'log_amount_sc': 1})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info.FIELD_DIMS_IN, info.FIELD_DIMS_NET, info.FIELD_DIMS_TAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batches(ds, buffer_size, batch_size):\n",
    "    return ds.cache().shuffle(buffer_size).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "n_seqs, n_steps, n_feat_inp = encoder.inp_tensor.shape\n",
    "x_tr, x_cv, inds_tr, inds_cv, targ_tr, targ_cv = train_test_split(encoder.inp_tensor, np.arange(n_seqs), encoder.tar_tensor, test_size=0.2)\n",
    "\n",
    "# Create TensorFlow dataset\n",
    "ds_all = tf.data.Dataset.from_tensor_slices((encoder.inp_tensor.astype(np.float32), encoder.tar_tensor.astype(np.float32)))\n",
    "ds_tr = tf.data.Dataset.from_tensor_slices((x_tr.astype(np.float32), targ_tr.astype(np.float32)))\n",
    "ds_cv = tf.data.Dataset.from_tensor_slices((x_cv.astype(np.float32), targ_cv.astype(np.float32)))\n",
    "\n",
    "BUFFER_SIZE = ds_all.cardinality().numpy()\n",
    "bs = 64  # batch size\n",
    "\n",
    "\n",
    "train_batches = make_batches(ds_tr, BUFFER_SIZE, bs)\n",
    "val_batches =  make_batches(ds_cv, BUFFER_SIZE, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import Train\n",
    "import tensorflow as tf\n",
    "from lib.modules import Transformer\n",
    "import time\n",
    "\n",
    "\n",
    "fieldInfo = FieldInfo(n_tcodes)\n",
    "config = {}\n",
    "config[\"ORDER\"] = fieldInfo.DATA_KEY_ORDER\n",
    "config[\"FIELD_STARTS_IN\"] = fieldInfo.FIELD_STARTS_IN\n",
    "config[\"FIELD_DIMS_IN\"] = fieldInfo.FIELD_DIMS_IN\n",
    "config[\"FIELD_STARTS_NET\"] = fieldInfo.FIELD_STARTS_NET\n",
    "config[\"FIELD_DIMS_NET\"] = fieldInfo.FIELD_DIMS_NET\n",
    "config[\"ACTIVATIONS\"] = fieldInfo.ACTIVATIONS\n",
    "\n",
    "features = 26\n",
    "d_embedding = 128\n",
    "dff = 128\n",
    "d_model = 128\n",
    "batch_size = 64\n",
    "seq_len = 80\n",
    "maximum_position_encoding = 256\n",
    "rate = 0.1\n",
    "num_heads = 2\n",
    "num_layers = 4\n",
    "raw_features = 7\n",
    "transformer = Transformer(features,dff, d_embedding, d_model, maximum_position_encoding,num_heads, num_layers,config, rate=0.1)\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "for (batch_no, (inp, tar)) in enumerate(train_batches):\n",
    "    if i == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'tcode_num': <tf.Tensor: shape=(64, 80, 16), dtype=float32, numpy=\n",
       "  array([[[ 2.9424188 ,  0.8550371 ,  1.5795753 , ..., -3.124101  ,\n",
       "           -3.768437  , -5.4478884 ],\n",
       "          [ 3.552644  ,  0.88985   ,  0.7321358 , ..., -2.5680518 ,\n",
       "           -3.6606238 , -4.490227  ],\n",
       "          [ 3.145526  ,  1.1573203 ,  0.586411  , ..., -2.8795938 ,\n",
       "           -3.7701976 , -4.9378543 ],\n",
       "          ...,\n",
       "          [ 2.9978514 ,  0.6749678 ,  2.5078201 , ..., -1.5712032 ,\n",
       "           -2.5768852 , -3.7554889 ],\n",
       "          [ 3.0091138 ,  0.2558116 ,  1.8602087 , ..., -1.2614082 ,\n",
       "           -3.0727384 , -4.3406644 ],\n",
       "          [ 2.930733  ,  0.9301025 ,  1.2812619 , ..., -1.3321704 ,\n",
       "           -3.4635432 , -4.421683  ]],\n",
       "  \n",
       "         [[ 2.7349777 ,  0.04985381,  2.1727483 , ..., -1.9930567 ,\n",
       "           -3.683842  , -4.177004  ],\n",
       "          [ 2.4216833 , -1.8766326 ,  1.9809875 , ..., -3.2038133 ,\n",
       "           -2.7369442 , -5.1841693 ],\n",
       "          [ 2.3031197 ,  1.4812559 ,  0.29817867, ..., -1.4796667 ,\n",
       "           -1.7533182 , -2.186785  ],\n",
       "          ...,\n",
       "          [-0.67447704, -0.8478969 ,  2.8241162 , ..., -1.4216896 ,\n",
       "           -3.1995065 , -2.435732  ],\n",
       "          [-0.5871997 , -0.93021286,  2.6782558 , ..., -1.0667939 ,\n",
       "           -2.724982  , -3.2815518 ],\n",
       "          [-0.0628282 , -0.79641324,  1.7191378 , ..., -0.89547235,\n",
       "           -4.383695  , -3.3412225 ]],\n",
       "  \n",
       "         [[ 3.502504  ,  1.3141263 ,  1.2890899 , ..., -1.8740568 ,\n",
       "           -3.4774332 , -4.226954  ],\n",
       "          [ 3.3252604 ,  1.549061  ,  2.2030077 , ..., -1.8650496 ,\n",
       "           -2.4445102 , -4.4902525 ],\n",
       "          [ 3.9291515 ,  1.2913972 ,  1.124819  , ..., -2.8605425 ,\n",
       "           -3.322302  , -4.7792096 ],\n",
       "          ...,\n",
       "          [ 3.633906  ,  1.4322239 , -1.5068038 , ..., -2.9500334 ,\n",
       "           -2.5012066 , -4.304658  ],\n",
       "          [ 4.359135  , -1.4017959 ,  3.0487912 , ...,  1.799868  ,\n",
       "           -0.7053563 , -3.5353827 ],\n",
       "          [ 3.8205917 , -0.901909  ,  2.9544535 , ...,  0.5791286 ,\n",
       "           -1.0160656 , -4.6724296 ]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[ 3.2593036 ,  0.81325126,  2.172068  , ..., -2.3889482 ,\n",
       "           -3.4167132 , -4.5650454 ],\n",
       "          [ 2.505577  , -0.5535294 ,  1.785821  , ..., -4.0866704 ,\n",
       "           -2.8962622 , -5.0719447 ],\n",
       "          [ 3.0914228 , -0.5530539 ,  2.5427291 , ..., -3.0161705 ,\n",
       "           -2.8357196 , -5.3796244 ],\n",
       "          ...,\n",
       "          [ 3.0746183 , -0.9373269 ,  1.029498  , ..., -0.4740205 ,\n",
       "           -1.6898698 , -3.9250436 ],\n",
       "          [ 2.8174925 , -0.9255586 ,  0.8444121 , ...,  0.22482929,\n",
       "           -1.2340828 , -3.6850657 ],\n",
       "          [ 3.0125928 , -0.7177372 ,  1.3036295 , ...,  0.49064136,\n",
       "           -1.1364468 , -3.7584202 ]],\n",
       "  \n",
       "         [[ 3.6671066 , -0.6770007 ,  1.1263196 , ..., -0.5543899 ,\n",
       "           -3.2243803 , -3.4943147 ],\n",
       "          [ 3.9807374 , -0.4889574 ,  3.6346164 , ..., -0.27639928,\n",
       "           -2.2215    , -3.5947905 ],\n",
       "          [ 3.0096123 , -0.27741978,  6.467253  , ...,  0.3425413 ,\n",
       "           -2.014057  , -3.0932736 ],\n",
       "          ...,\n",
       "          [ 2.27404   , -1.4944961 ,  3.6577573 , ...,  1.8643869 ,\n",
       "           -1.1026108 , -2.729714  ],\n",
       "          [-0.85703784, -1.5585132 ,  6.8558955 , ..., -0.07240364,\n",
       "           -3.559906  , -1.8876073 ],\n",
       "          [-0.84292835, -1.149367  ,  0.6498296 , ..., -0.3348217 ,\n",
       "           -3.8904345 , -2.0150366 ]],\n",
       "  \n",
       "         [[ 3.158774  ,  1.3916161 ,  2.7611504 , ..., -2.8280258 ,\n",
       "           -3.5084753 , -5.065384  ],\n",
       "          [ 2.8639464 ,  1.3687611 ,  1.3293419 , ..., -2.547818  ,\n",
       "           -3.6958597 , -4.9589252 ],\n",
       "          [ 2.349167  ,  1.6559194 , -1.3999519 , ..., -2.9596994 ,\n",
       "           -3.139095  , -4.205217  ],\n",
       "          ...,\n",
       "          [ 2.4562366 ,  0.4719463 , -0.71682775, ..., -3.250058  ,\n",
       "           -3.4631062 , -4.0916166 ],\n",
       "          [ 2.5458758 , -0.62141836,  3.368452  , ..., -2.6963158 ,\n",
       "           -1.9675353 , -4.992581  ],\n",
       "          [ 2.6677516 , -1.2664216 ,  3.6508477 , ..., -1.5267653 ,\n",
       "           -1.8091975 , -4.7525296 ]]], dtype=float32)>,\n",
       "  'dow': <tf.Tensor: shape=(64, 80, 7), dtype=float32, numpy=\n",
       "  array([[[ 1.1769660e+00,  6.8240190e-01,  6.1689723e-01, ...,\n",
       "            1.4517184e+00,  1.3911462e+00,  1.0162613e+00],\n",
       "          [ 1.1175559e+00,  8.0863750e-01,  7.2711539e-01, ...,\n",
       "            1.1248389e+00,  4.3264523e-01,  9.9749798e-01],\n",
       "          [ 9.3847251e-01,  6.8118203e-01,  9.8472816e-01, ...,\n",
       "            7.9891723e-01,  7.2178543e-01,  1.0146947e+00],\n",
       "          ...,\n",
       "          [ 7.9137258e-02,  4.6932456e-01, -2.7765092e-01, ...,\n",
       "            6.5970969e-01,  3.9731166e-01,  2.6906919e-01],\n",
       "          [ 5.8476871e-01,  5.1747149e-01,  4.7958791e-01, ...,\n",
       "            3.4072331e-01,  7.8556441e-02,  2.3746574e-02],\n",
       "          [-2.4937552e-01,  6.6548979e-01,  3.5274059e-01, ...,\n",
       "            1.0590750e+00,  2.6517475e-01,  4.0551430e-01]],\n",
       "  \n",
       "         [[ 4.6159911e-01,  2.3555474e-01,  5.1715952e-01, ...,\n",
       "            6.2999666e-01,  1.1406307e+00,  7.0021451e-01],\n",
       "          [ 9.9856842e-01,  1.6992496e+00,  9.4532889e-01, ...,\n",
       "            1.5066007e+00,  1.8445231e+00,  1.0453709e+00],\n",
       "          [ 3.8439233e-02,  4.4936530e-02, -1.8766606e-01, ...,\n",
       "            1.3013445e-01,  5.4446745e-01, -2.1676453e-02],\n",
       "          ...,\n",
       "          [-2.9647908e-01, -1.7004262e-01, -3.4546807e-02, ...,\n",
       "            1.7084365e-01, -5.9835583e-01, -3.5254556e-01],\n",
       "          [-1.9504368e-01, -4.7947282e-01,  2.9288971e-01, ...,\n",
       "            1.2805265e-01, -9.2752528e-01, -3.9691684e-01],\n",
       "          [-2.7693105e-01,  5.4587775e-01,  1.5253197e-02, ...,\n",
       "            1.1512700e-01, -1.0093468e+00, -3.8341606e-01]],\n",
       "  \n",
       "         [[ 1.4795340e+00,  6.6871065e-01,  8.4711540e-01, ...,\n",
       "            9.1599262e-01,  1.1485151e+00,  1.0224742e+00],\n",
       "          [ 8.6540568e-01,  5.0663733e-01,  3.6059737e-01, ...,\n",
       "            8.8384694e-01,  1.0048643e+00,  1.1376599e+00],\n",
       "          [ 4.7073257e-01,  7.4215525e-01,  1.2482715e+00, ...,\n",
       "            6.5712547e-01,  6.1441857e-01,  4.9602634e-01],\n",
       "          ...,\n",
       "          [ 6.9299698e-01,  4.3241709e-01,  9.4909978e-01, ...,\n",
       "            8.3144760e-01,  9.7564399e-01,  9.2454517e-01],\n",
       "          [ 5.8413118e-01,  7.5699532e-01,  5.5907679e-01, ...,\n",
       "            5.2820033e-01,  7.3684597e-01,  8.4472835e-01],\n",
       "          [ 7.2524071e-01,  4.9323794e-01,  9.3021607e-01, ...,\n",
       "            6.9244921e-01,  5.7932526e-01,  1.3396567e+00]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[ 5.0393111e-01,  4.1403666e-01,  4.2475596e-01, ...,\n",
       "            1.1561344e+00,  8.7979114e-01,  5.8754677e-01],\n",
       "          [ 1.9782013e+00,  1.3982246e+00,  9.0128160e-01, ...,\n",
       "            1.2038808e+00,  1.6588244e+00,  1.1217167e+00],\n",
       "          [ 1.5838805e+00,  1.2087277e+00,  1.2579618e+00, ...,\n",
       "            1.1776911e+00,  1.4016920e+00,  1.3785096e+00],\n",
       "          ...,\n",
       "          [ 1.2428168e+00,  9.8453790e-01,  5.4643643e-01, ...,\n",
       "            7.9572356e-01,  1.1457950e+00,  6.0373509e-01],\n",
       "          [ 1.0662172e+00,  5.7257205e-01,  8.5528016e-01, ...,\n",
       "            1.0302529e+00,  8.0731946e-01,  8.1117928e-01],\n",
       "          [ 5.7207680e-01,  3.6387926e-01,  6.9531876e-01, ...,\n",
       "            6.6616237e-01,  3.1516621e-01,  6.8504339e-01]],\n",
       "  \n",
       "         [[ 1.1633977e+00,  1.0519583e+00,  8.4515578e-01, ...,\n",
       "            8.4812325e-01,  1.3432008e+00,  1.1093131e+00],\n",
       "          [ 3.5184151e-01,  1.1214725e+00, -2.9338741e-01, ...,\n",
       "            4.8803332e-01, -8.8280765e-04,  8.8083667e-01],\n",
       "          [-3.8280508e-01, -2.1358089e-01, -7.0883207e-02, ...,\n",
       "            5.6193733e-01, -3.4503654e-01,  4.2682061e-01],\n",
       "          ...,\n",
       "          [ 2.6761067e-01,  4.6684715e-01,  2.5165805e-01, ...,\n",
       "            3.6388409e-01,  1.3437447e-01,  9.2952222e-02],\n",
       "          [ 2.2725220e-01, -7.4457723e-01, -9.5049001e-02, ...,\n",
       "           -1.6421056e-01, -6.1180156e-01, -4.0604326e-01],\n",
       "          [ 6.9063947e-02, -4.5660928e-01, -1.6588676e-01, ...,\n",
       "           -1.9739701e-01, -7.1782809e-01, -1.0770841e-01]],\n",
       "  \n",
       "         [[ 3.5584381e-01,  3.7295258e-01,  2.4816889e-01, ...,\n",
       "            1.0444093e+00,  1.2252122e+00,  9.4719797e-01],\n",
       "          [ 7.8506356e-01,  5.9961140e-01,  3.4043062e-01, ...,\n",
       "            1.0432048e+00,  1.3128912e+00,  1.0446848e+00],\n",
       "          [ 6.9737017e-01,  3.3828160e-01,  5.2986801e-01, ...,\n",
       "            1.0768064e+00,  6.5419912e-01,  1.2298676e+00],\n",
       "          ...,\n",
       "          [ 7.7098912e-01,  3.6316618e-01,  6.7919308e-01, ...,\n",
       "            1.0169456e+00,  7.6370293e-01,  9.5769626e-01],\n",
       "          [ 1.2168801e+00,  8.8626111e-01,  1.0878335e+00, ...,\n",
       "            1.0275719e+00,  7.8835982e-01,  9.3221933e-01],\n",
       "          [ 1.2653663e+00,  9.4326454e-01,  1.2403715e+00, ...,\n",
       "            1.1543783e+00,  9.7851807e-01,  1.2703978e+00]]], dtype=float32)>,\n",
       "  'month': <tf.Tensor: shape=(64, 80, 12), dtype=float32, numpy=\n",
       "  array([[[ 1.0542608 ,  0.3223955 ,  0.10856851, ...,  0.9289598 ,\n",
       "            0.7356456 ,  0.71143115],\n",
       "          [ 0.39670184,  0.9537644 ,  0.5375813 , ...,  0.10831744,\n",
       "            0.11064564,  0.19441488],\n",
       "          [ 1.0982331 ,  0.91612977,  0.6906745 , ...,  0.7302256 ,\n",
       "            0.4077691 ,  0.55585265],\n",
       "          ...,\n",
       "          [ 0.44347006,  0.73380464,  0.08023211, ..., -0.31211054,\n",
       "           -0.06557918, -0.29835388],\n",
       "          [ 1.0725377 ,  1.7865386 ,  0.73106176, ..., -0.9137253 ,\n",
       "            0.68393624,  0.6336773 ],\n",
       "          [ 0.74032503,  0.73750347,  0.33475873, ..., -0.40435597,\n",
       "            0.09537482, -0.22950843]],\n",
       "  \n",
       "         [[ 1.1396489 ,  1.0601122 ,  0.5450288 , ...,  1.1393703 ,\n",
       "            1.4634395 ,  0.6014816 ],\n",
       "          [-0.11138225,  0.8375132 ,  0.2508969 , ..., -0.5343934 ,\n",
       "            0.43980774, -0.50431573],\n",
       "          [-0.65417117, -2.0650256 , -0.53479266, ...,  1.1034534 ,\n",
       "            0.23677243, -0.06966031],\n",
       "          ...,\n",
       "          [ 0.09899497,  1.0210476 ,  0.21265346, ..., -0.84799194,\n",
       "            0.22300713, -0.07666253],\n",
       "          [ 0.80636847,  2.079329  ,  0.73107475, ..., -0.7143768 ,\n",
       "            0.30197883,  0.06859848],\n",
       "          [ 0.97738343,  1.071201  , -0.01894039, ..., -0.13851279,\n",
       "            0.4192709 ,  0.44017434]],\n",
       "  \n",
       "         [[ 0.08965899,  0.09792857,  0.72560555, ...,  1.2421861 ,\n",
       "            1.0935899 ,  0.3360591 ],\n",
       "          [ 0.20930597,  0.04251479,  0.4981776 , ...,  0.578324  ,\n",
       "            0.64158624,  0.74204475],\n",
       "          [ 0.3606669 ,  0.11379957,  0.8667849 , ...,  0.23463872,\n",
       "            0.21055277, -0.54304355],\n",
       "          ...,\n",
       "          [-0.7070922 , -0.5582171 , -0.54956025, ..., -0.41926888,\n",
       "           -0.02648346, -0.8390802 ],\n",
       "          [ 0.42416877, -0.15511729,  0.36623666, ...,  0.27835637,\n",
       "            0.44341666,  0.3356375 ],\n",
       "          [ 0.49877468,  0.22580898,  0.45051634, ..., -0.15150252,\n",
       "            0.29307705, -0.42038107]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[ 0.7468734 ,  0.607391  ,  0.06031147, ...,  1.6496295 ,\n",
       "            0.8790838 ,  0.3320013 ],\n",
       "          [ 1.0047666 ,  1.741466  ,  0.45710284, ...,  0.27802828,\n",
       "            0.45265275,  0.3529323 ],\n",
       "          [ 0.93976647,  2.1348505 ,  0.65677774, ...,  0.51329416,\n",
       "            0.49102685,  1.0182832 ],\n",
       "          ...,\n",
       "          [ 1.1362141 ,  1.8810439 ,  0.03368213, ..., -0.45203462,\n",
       "           -0.21469142,  0.14134923],\n",
       "          [ 0.8499601 ,  2.1301718 ,  0.71387726, ..., -0.6075073 ,\n",
       "            0.33819637,  0.5963504 ],\n",
       "          [ 0.88957214,  1.5370971 ,  0.49364263, ..., -0.38565806,\n",
       "            0.28728727,  0.6928551 ]],\n",
       "  \n",
       "         [[ 0.55522305,  1.1035863 ,  0.58360296, ..., -0.09387608,\n",
       "            0.78280383,  0.25762376],\n",
       "          [-0.12275882,  0.38234907,  0.48558334, ...,  0.39226943,\n",
       "            0.7956764 , -0.1565075 ],\n",
       "          [ 0.4237428 , -0.40279803,  0.40806207, ...,  1.0124285 ,\n",
       "            0.783068  , -0.06964843],\n",
       "          ...,\n",
       "          [ 0.57891136, -0.02702906,  0.02460232, ...,  0.76554936,\n",
       "            0.6324879 ,  0.9374906 ],\n",
       "          [ 1.816687  ,  1.6150448 ,  0.21276584, ...,  0.19126043,\n",
       "            1.2875736 ,  0.9980927 ],\n",
       "          [ 0.877985  ,  2.3298066 ,  1.2151513 , ..., -0.2631738 ,\n",
       "           -0.26047808,  0.73642606]],\n",
       "  \n",
       "         [[ 0.6191157 , -0.31866387,  0.14934924, ...,  1.6377765 ,\n",
       "            0.75259125, -0.0582242 ],\n",
       "          [ 0.74917984,  0.23834732,  0.4605271 , ...,  1.1056964 ,\n",
       "            0.02393655,  0.21334833],\n",
       "          [ 1.0612239 ,  0.18636495,  0.44283432, ...,  1.5545018 ,\n",
       "            0.18438135,  1.0876496 ],\n",
       "          ...,\n",
       "          [ 0.32427835,  0.16355039, -0.00870053, ...,  0.26769507,\n",
       "           -0.08428585,  0.3646033 ],\n",
       "          [ 0.40551612,  0.30925167,  0.09030426, ...,  0.4279069 ,\n",
       "            0.7767751 , -0.01930462],\n",
       "          [-0.11358078,  0.6013884 ,  0.5623431 , ..., -0.5765044 ,\n",
       "            0.28945327,  0.31298468]]], dtype=float32)>,\n",
       "  'day': <tf.Tensor: shape=(64, 80, 31), dtype=float32, numpy=\n",
       "  array([[[ 1.9229107 ,  0.51180553, -0.13148302, ..., -0.33307877,\n",
       "           -0.42451826,  1.3447297 ],\n",
       "          [ 1.3939422 ,  0.69280684, -0.4425061 , ..., -0.56409353,\n",
       "           -0.6054082 ,  0.93987834],\n",
       "          [ 1.7698802 , -0.40323517, -0.8474359 , ..., -0.97172767,\n",
       "           -0.19583173,  1.0021093 ],\n",
       "          ...,\n",
       "          [ 3.6320183 ,  0.22199647,  0.37093577, ...,  0.73512655,\n",
       "            0.51853925,  2.579286  ],\n",
       "          [ 3.9989908 , -0.02865576, -0.3710942 , ...,  0.824904  ,\n",
       "            0.80158997,  2.4866521 ],\n",
       "          [ 4.1456056 ,  1.0190258 ,  0.33145383, ...,  0.34640124,\n",
       "            0.46758312,  2.5123239 ]],\n",
       "  \n",
       "         [[ 2.3334067 , -0.6466066 , -0.8581122 , ..., -0.5372728 ,\n",
       "           -0.57685083,  1.7437096 ],\n",
       "          [ 2.6880724 , -2.8749623 , -3.6851022 , ...,  0.16111292,\n",
       "           -0.1756817 ,  1.6656679 ],\n",
       "          [-0.49509335, -0.18131113, -0.56459343, ..., -2.530316  ,\n",
       "           -2.6616325 , -0.45246625],\n",
       "          ...,\n",
       "          [ 3.319046  ,  1.0641125 , -0.63278025, ..., -0.02573617,\n",
       "           -0.34532934,  2.4640105 ],\n",
       "          [ 3.9236052 , -0.575511  , -0.6835589 , ...,  1.1331929 ,\n",
       "            0.3429084 ,  2.4668431 ],\n",
       "          [ 3.031732  ,  0.45596835,  0.46358386, ..., -0.42125273,\n",
       "           -0.07084592,  1.9492221 ]],\n",
       "  \n",
       "         [[ 2.5378652 , -0.59550196, -0.88814133, ..., -0.09725083,\n",
       "           -0.3712757 ,  1.136693  ],\n",
       "          [ 2.6648517 , -0.42661095,  0.01805737, ..., -0.04435953,\n",
       "           -0.18823837,  0.93208694],\n",
       "          [ 2.0464177 ,  0.05030119, -0.3169979 , ..., -1.3633448 ,\n",
       "           -0.8615069 ,  0.681902  ],\n",
       "          ...,\n",
       "          [ 0.5828271 , -0.66843414, -2.1255655 , ..., -2.0840423 ,\n",
       "           -2.6033387 , -1.1802317 ],\n",
       "          [ 4.2280464 , -1.5271258 , -0.98580253, ...,  2.178892  ,\n",
       "            1.9191906 ,  3.8053222 ],\n",
       "          [ 4.4961786 , -1.6440419 , -1.7061577 , ...,  1.9010723 ,\n",
       "            1.814642  ,  3.259092  ]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[ 1.8338134 ,  0.7361996 , -0.03035947, ...,  0.19772995,\n",
       "            0.19887434,  1.6852877 ],\n",
       "          [ 1.280839  , -1.6860149 , -2.6587727 , ...,  0.78315705,\n",
       "            0.59350574,  1.3388138 ],\n",
       "          [ 2.266039  , -1.4174781 , -2.6226056 , ...,  1.4075574 ,\n",
       "            1.3481768 ,  2.2160263 ],\n",
       "          ...,\n",
       "          [ 2.8634045 , -1.0926356 , -1.1156088 , ...,  1.7702999 ,\n",
       "            2.0210147 ,  2.4074404 ],\n",
       "          [ 3.6729696 , -1.1129475 , -1.233631  , ...,  2.4634397 ,\n",
       "            2.2443645 ,  1.9938102 ],\n",
       "          [ 3.5833406 , -1.3841923 , -1.2706064 , ...,  2.8540037 ,\n",
       "            2.1710355 ,  2.0802052 ]],\n",
       "  \n",
       "         [[ 1.5795401 ,  0.74596536,  0.00770914, ...,  0.4517588 ,\n",
       "           -0.4037862 ,  1.2175049 ],\n",
       "          [ 3.7758877 , -1.538364  , -1.6122704 , ...,  1.3940262 ,\n",
       "            1.0255538 ,  3.7714977 ],\n",
       "          [ 5.0739083 ,  1.2827861 ,  0.37604207, ...,  1.1503471 ,\n",
       "            0.45771432,  4.497675  ],\n",
       "          ...,\n",
       "          [ 5.3673816 , -1.5087265 , -0.83248115, ...,  3.3804271 ,\n",
       "            2.5454876 ,  5.3924437 ],\n",
       "          [ 4.65282   ,  1.3053269 ,  0.10781561, ...,  1.6743125 ,\n",
       "            1.565357  ,  3.8059707 ],\n",
       "          [ 0.04448586,  1.1696742 ,  0.46186984, ..., -1.3782232 ,\n",
       "           -1.215316  , -0.6305351 ]],\n",
       "  \n",
       "         [[ 3.00602   ,  0.17264444, -0.5108711 , ...,  0.4951019 ,\n",
       "           -0.56742936,  2.637369  ],\n",
       "          [ 0.9849806 ,  0.37742755, -0.29525894, ..., -0.48666802,\n",
       "           -0.40975782,  1.5096625 ],\n",
       "          [-0.44199103, -0.1389586 , -1.0189232 , ..., -1.5051049 ,\n",
       "           -1.4316853 , -1.30548   ],\n",
       "          ...,\n",
       "          [ 0.09258322, -1.1027358 , -2.4014838 , ..., -2.5509877 ,\n",
       "           -2.6766574 , -0.98383826],\n",
       "          [ 2.0110488 , -2.6047678 , -4.3876557 , ..., -0.508621  ,\n",
       "            0.02845746,  1.9639333 ],\n",
       "          [ 3.734929  , -2.857898  , -4.5078597 , ...,  1.7523943 ,\n",
       "            0.17512879,  2.5742443 ]]], dtype=float32)>,\n",
       "  'dtme': <tf.Tensor: shape=(64, 80, 31), dtype=float32, numpy=\n",
       "  array([[[ 2.8736246e+00, -7.9040933e-01, -4.5190817e-01, ...,\n",
       "            6.2501365e-01,  3.9825141e-01, -4.0059131e-01],\n",
       "          [ 1.9371606e+00, -5.1391888e-01, -7.6836687e-01, ...,\n",
       "            1.0432685e-01,  1.4004043e-01, -3.9278960e-01],\n",
       "          [ 2.2381573e+00, -5.2585131e-01, -7.1329749e-01, ...,\n",
       "            5.3112932e-02,  4.3658197e-01, -8.4125876e-01],\n",
       "          ...,\n",
       "          [ 4.5505576e+00,  8.4460104e-01, -5.6565666e-01, ...,\n",
       "            4.1009912e-01, -2.8905821e-01, -4.9583245e-02],\n",
       "          [ 4.5936117e+00,  8.9686435e-01, -2.5825951e-01, ...,\n",
       "            7.9823965e-01, -9.4483566e-01,  1.8108696e-01],\n",
       "          [ 5.1814251e+00,  6.6340083e-01, -6.9771135e-01, ...,\n",
       "            1.4900852e+00,  2.1299718e-01,  9.9475282e-01]],\n",
       "  \n",
       "         [[ 3.1365657e+00, -1.4130036e+00,  1.0510306e-01, ...,\n",
       "            5.3082412e-01, -7.0189458e-01, -1.5206788e+00],\n",
       "          [ 2.5580103e+00, -1.6713876e-01, -1.0302833e+00, ...,\n",
       "           -2.3740268e+00, -1.1613259e+00, -3.5494237e+00],\n",
       "          [-9.2051852e-01, -3.0857296e+00, -3.4126873e+00, ...,\n",
       "           -8.8923562e-01,  4.4221479e-01, -1.6512148e+00],\n",
       "          ...,\n",
       "          [ 4.2155004e+00, -1.4817973e+00, -1.9554945e+00, ...,\n",
       "            6.1333269e-01, -3.7355492e-01,  4.9222030e-02],\n",
       "          [ 4.8319011e+00, -3.0118066e-01, -1.0057032e+00, ...,\n",
       "            7.0723170e-01, -8.2186174e-01, -1.3239954e-01],\n",
       "          [ 3.9892709e+00, -1.2777960e+00, -2.1542592e+00, ...,\n",
       "            1.4209901e+00, -9.0675339e-02,  8.8294244e-01]],\n",
       "  \n",
       "         [[ 2.9781888e+00, -8.3947957e-02,  5.4777926e-01, ...,\n",
       "            1.1292410e+00,  2.2156252e-01,  1.5576039e-01],\n",
       "          [ 2.9196711e+00, -4.4311132e-02, -4.5217112e-01, ...,\n",
       "            1.1880604e+00,  3.1568110e-01, -2.7997789e-01],\n",
       "          [ 1.8799894e+00, -1.1176189e+00, -6.3491809e-01, ...,\n",
       "           -7.2168016e-01,  2.7347398e-01, -8.8664186e-01],\n",
       "          ...,\n",
       "          [ 1.1420468e+00, -1.0957479e+00, -1.4428209e+00, ...,\n",
       "           -1.4741451e+00, -1.7555256e+00, -1.7873889e+00],\n",
       "          [ 5.8460984e+00,  3.0781913e+00,  3.2041364e+00, ...,\n",
       "           -7.4849856e-01, -1.1388748e+00, -9.3695062e-01],\n",
       "          [ 6.0447783e+00,  2.9584615e+00,  2.6031609e+00, ...,\n",
       "           -7.0133984e-01, -1.0448306e+00, -1.5486362e+00]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[ 2.8961959e+00, -8.5432088e-01, -1.5598281e-01, ...,\n",
       "            1.0661926e+00,  3.3547240e-01, -9.9257268e-03],\n",
       "          [ 2.3217602e+00,  4.6444678e-01,  2.5548667e-01, ...,\n",
       "           -2.1429381e+00, -1.2233356e+00, -2.7033958e+00],\n",
       "          [ 3.6380146e+00,  1.3358415e+00,  1.1129546e+00, ...,\n",
       "           -1.3711687e+00, -8.1904978e-01, -1.7806888e+00],\n",
       "          ...,\n",
       "          [ 4.2432303e+00,  2.4192011e+00,  1.8331420e+00, ...,\n",
       "           -1.1476687e+00, -1.1269971e+00, -6.5976232e-01],\n",
       "          [ 4.7623606e+00,  3.0799322e+00,  2.4408760e+00, ...,\n",
       "           -2.6859644e-01, -1.6077737e+00, -1.8621549e-01],\n",
       "          [ 5.5443454e+00,  3.7813623e+00,  3.0872281e+00, ...,\n",
       "           -3.3093113e-01, -1.1838590e+00, -3.5890707e-01]],\n",
       "  \n",
       "         [[ 2.8703773e+00, -3.8310325e-01,  6.9376606e-01, ...,\n",
       "            7.0003772e-01, -2.1917006e-01, -2.2160754e-01],\n",
       "          [ 4.9288969e+00,  1.7600604e+00,  9.3421346e-01, ...,\n",
       "           -8.4920192e-01, -1.1029482e+00, -7.9482001e-01],\n",
       "          [ 6.2993493e+00,  6.4635003e-01, -4.6969216e-02, ...,\n",
       "            2.3936011e-01,  6.2742643e-03,  8.6942774e-01],\n",
       "          ...,\n",
       "          [ 7.1514502e+00,  2.8023479e+00,  2.9563103e+00, ...,\n",
       "           -6.0273719e-01, -1.3641845e+00, -3.9228606e-01],\n",
       "          [ 5.9056993e+00,  6.3170332e-01, -6.8450615e-02, ...,\n",
       "            1.1299493e+00,  5.5160773e-01,  6.6850078e-01],\n",
       "          [ 7.2867769e-01, -2.9384050e+00, -3.1032250e+00, ...,\n",
       "            1.5874122e+00,  1.0888313e+00,  6.0943890e-01]],\n",
       "  \n",
       "         [[ 4.5601802e+00, -1.4779463e-01, -3.9389011e-01, ...,\n",
       "            7.3042434e-01,  6.6786712e-01, -3.1042919e-02],\n",
       "          [ 2.1477132e+00, -7.9819334e-01, -1.3083445e+00, ...,\n",
       "            4.2495209e-01,  8.2140619e-01, -3.9477742e-01],\n",
       "          [-2.9945284e-01, -2.1238151e+00, -2.7010279e+00, ...,\n",
       "           -4.4409797e-01,  5.0468087e-01, -4.6266541e-01],\n",
       "          ...,\n",
       "          [ 6.0970330e-01, -2.2602267e+00, -2.4403341e+00, ...,\n",
       "           -1.5750883e+00, -1.7463552e+00, -2.6702750e+00],\n",
       "          [ 2.2142479e+00,  2.0516635e-01,  1.5561658e-01, ...,\n",
       "           -3.4047711e+00, -3.1102796e+00, -4.3745522e+00],\n",
       "          [ 3.9866073e+00,  1.4440889e+00,  1.2954925e+00, ...,\n",
       "           -3.0892556e+00, -3.0595002e+00, -3.6078980e+00]]], dtype=float32)>,\n",
       "  'td_sc': <tf.Tensor: shape=(64, 80, 2), dtype=float32, numpy=\n",
       "  array([[[0.        , 0.        ],\n",
       "          [0.        , 0.9357255 ],\n",
       "          [0.        , 0.43878442],\n",
       "          ...,\n",
       "          [0.        , 0.        ],\n",
       "          [0.        , 0.        ],\n",
       "          [0.        , 0.        ]],\n",
       "  \n",
       "         [[0.        , 0.        ],\n",
       "          [0.        , 2.0562916 ],\n",
       "          [0.        , 3.0567193 ],\n",
       "          ...,\n",
       "          [0.        , 0.        ],\n",
       "          [0.        , 0.        ],\n",
       "          [0.        , 0.        ]],\n",
       "  \n",
       "         [[0.        , 0.38977402],\n",
       "          [0.        , 1.3842921 ],\n",
       "          [0.        , 1.4833951 ],\n",
       "          ...,\n",
       "          [0.        , 0.12600824],\n",
       "          [0.        , 0.        ],\n",
       "          [0.        , 0.03885129]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[0.        , 0.        ],\n",
       "          [0.        , 1.0876304 ],\n",
       "          [0.        , 0.9347369 ],\n",
       "          ...,\n",
       "          [0.        , 0.47938743],\n",
       "          [0.        , 0.232035  ],\n",
       "          [0.        , 0.        ]],\n",
       "  \n",
       "         [[0.        , 0.        ],\n",
       "          [0.        , 1.1212453 ],\n",
       "          [0.        , 0.05557431],\n",
       "          ...,\n",
       "          [0.        , 0.        ],\n",
       "          [0.        , 0.        ],\n",
       "          [0.        , 0.        ]],\n",
       "  \n",
       "         [[0.        , 0.8652515 ],\n",
       "          [0.        , 0.7248946 ],\n",
       "          [0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.        ],\n",
       "          [0.        , 0.74519396],\n",
       "          [0.        , 1.8577999 ]]], dtype=float32)>,\n",
       "  'log_amount_sc': <tf.Tensor: shape=(64, 80, 1), dtype=float32, numpy=\n",
       "  array([[[0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          ...,\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.]],\n",
       "  \n",
       "         [[0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          ...,\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.]],\n",
       "  \n",
       "         [[0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          ...,\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          ...,\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.]],\n",
       "  \n",
       "         [[0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          ...,\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.]],\n",
       "  \n",
       "         [[0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          ...,\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.]]], dtype=float32)>},\n",
       " {'decoder_layer1': <tf.Tensor: shape=(64, 2, 80, 80), dtype=float32, numpy=\n",
       "  array([[[[1.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "            0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "           [3.8137537e-01, 6.1862463e-01, 0.0000000e+00, ...,\n",
       "            0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "           [2.2814514e-01, 3.4707037e-01, 4.2478451e-01, ...,\n",
       "            0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "           ...,\n",
       "           [2.8221782e-02, 3.5781957e-02, 3.1657044e-02, ...,\n",
       "            0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "           [3.2996126e-02, 3.9580442e-02, 3.5741009e-02, ...,\n",
       "            0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "           [2.7053781e-02, 3.5539817e-02, 3.2426443e-02, ...,\n",
       "            0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
       "  \n",
       "          [[1.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "            0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "           [3.4091493e-01, 6.5908509e-01, 0.0000000e+00, ...,\n",
       "            0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "           [1.3402987e-01, 3.0519259e-01, 5.6077754e-01, ...,\n",
       "            0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "           ...,\n",
       "           [1.8190598e-02, 3.5176240e-02, 7.2519571e-02, ...,\n",
       "            0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "           [1.8877611e-02, 3.8847655e-02, 7.6394044e-02, ...,\n",
       "            0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "           [1.4638260e-02, 3.0755064e-02, 6.5617949e-02, ...,\n",
       "            0.0000000e+00, 0.0000000e+00, 0.0000000e+00]]],\n",
       "  \n",
       "  \n",
       "         [[[1.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "            0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "           [9.3110800e-02, 9.0688920e-01, 0.0000000e+00, ...,\n",
       "            0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "           [9.8295651e-02, 4.0441000e-01, 4.9729437e-01, ...,\n",
       "            0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "           ...,\n",
       "           [6.0362299e-03, 5.5255839e-03, 6.8054050e-03, ...,\n",
       "            0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "           [6.5379366e-03, 4.8285010e-03, 7.6386947e-03, ...,\n",
       "            0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "           [6.0866727e-03, 5.2498542e-03, 7.9404656e-03, ...,\n",
       "            0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
       "  \n",
       "          [[1.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "            0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "           [8.3250040e-01, 1.6749956e-01, 0.0000000e+00, ...,\n",
       "            0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "           [8.6887056e-01, 4.4103280e-02, 8.7026209e-02, ...,\n",
       "            0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "           ...,\n",
       "           [7.3682201e-01, 1.6461752e-03, 2.6415337e-03, ...,\n",
       "            0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "           [7.0634300e-01, 2.1771009e-03, 3.0582666e-03, ...,\n",
       "            0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "           [7.1906525e-01, 1.6774760e-03, 2.6386075e-03, ...,\n",
       "            0.0000000e+00, 0.0000000e+00, 0.0000000e+00]]],\n",
       "  \n",
       "  \n",
       "         [[[1.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "            0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "           [2.7567494e-01, 7.2432506e-01, 0.0000000e+00, ...,\n",
       "            0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "           [1.6884518e-01, 2.5752974e-01, 5.7362509e-01, ...,\n",
       "            0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "           ...,\n",
       "           [4.1562822e-03, 1.6276597e-03, 3.5194308e-03, ...,\n",
       "            2.2133959e-02, 0.0000000e+00, 0.0000000e+00],\n",
       "           [5.1785163e-03, 6.8291705e-03, 6.5563219e-03, ...,\n",
       "            5.6509636e-03, 4.6124682e-03, 0.0000000e+00],\n",
       "           [5.2371882e-03, 5.3119361e-03, 7.2010919e-03, ...,\n",
       "            1.4753913e-02, 5.6236261e-03, 1.0758782e-02]],\n",
       "  \n",
       "          [[1.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "            0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "           [6.7861325e-01, 3.2138675e-01, 0.0000000e+00, ...,\n",
       "            0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "           [2.2671522e-01, 1.2848058e-01, 6.4480418e-01, ...,\n",
       "            0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "           ...,\n",
       "           [2.8495800e-02, 3.6130191e-03, 3.7926473e-02, ...,\n",
       "            2.6988668e-02, 0.0000000e+00, 0.0000000e+00],\n",
       "           [6.0406015e-03, 3.0922364e-03, 5.3806538e-03, ...,\n",
       "            1.2915778e-02, 2.6439197e-02, 0.0000000e+00],\n",
       "           [7.7806828e-03, 2.2769524e-03, 1.0093281e-02, ...,\n",
       "            1.8565366e-02, 3.3741988e-02, 1.8729871e-02]]],\n",
       "  \n",
       "  \n",
       "         ...,\n",
       "  \n",
       "  \n",
       "         [[[1.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "            0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "           [2.2005364e-01, 7.7994633e-01, 0.0000000e+00, ...,\n",
       "            0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "           [9.9685237e-02, 3.6436173e-01, 5.3595304e-01, ...,\n",
       "            0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "           ...,\n",
       "           [4.3333089e-03, 7.5172428e-03, 6.9154771e-03, ...,\n",
       "            6.2637799e-03, 0.0000000e+00, 0.0000000e+00],\n",
       "           [5.4738014e-03, 6.1362945e-03, 5.3338995e-03, ...,\n",
       "            5.6437091e-03, 9.8093702e-03, 0.0000000e+00],\n",
       "           [4.6577035e-03, 4.4641239e-03, 3.4864955e-03, ...,\n",
       "            6.0910871e-03, 9.2379162e-03, 8.8534709e-03]],\n",
       "  \n",
       "          [[1.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "            0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "           [5.5255699e-01, 4.4744301e-01, 0.0000000e+00, ...,\n",
       "            0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "           [3.0490234e-01, 3.0721438e-01, 3.8788325e-01, ...,\n",
       "            0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "           ...,\n",
       "           [1.6947672e-02, 5.3426079e-03, 7.3990123e-03, ...,\n",
       "            1.5906803e-02, 0.0000000e+00, 0.0000000e+00],\n",
       "           [1.8319042e-02, 6.7733414e-03, 9.3607511e-03, ...,\n",
       "            1.9326994e-02, 2.3638420e-02, 0.0000000e+00],\n",
       "           [1.4036080e-02, 5.0108223e-03, 7.0698406e-03, ...,\n",
       "            1.7207237e-02, 2.1561068e-02, 2.9096499e-02]]],\n",
       "  \n",
       "  \n",
       "         [[[1.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "            0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "           [3.3218986e-01, 6.6781020e-01, 0.0000000e+00, ...,\n",
       "            0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "           [4.8689094e-01, 8.7655894e-02, 4.2545313e-01, ...,\n",
       "            0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "           ...,\n",
       "           [1.1119845e-02, 2.0139739e-03, 4.2615836e-03, ...,\n",
       "            1.4353259e-02, 0.0000000e+00, 0.0000000e+00],\n",
       "           [9.9984528e-03, 7.9607038e-04, 2.0301344e-03, ...,\n",
       "            9.7709494e-03, 4.2451195e-02, 0.0000000e+00],\n",
       "           [5.0246953e-03, 7.2910060e-04, 6.2982697e-04, ...,\n",
       "            3.3547385e-03, 3.8523471e-03, 7.8020967e-03]],\n",
       "  \n",
       "          [[1.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "            0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "           [7.2248721e-01, 2.7751279e-01, 0.0000000e+00, ...,\n",
       "            0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "           [6.5077859e-01, 1.5985242e-01, 1.8936895e-01, ...,\n",
       "            0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "           ...,\n",
       "           [9.0112254e-02, 3.7122285e-03, 2.6466916e-03, ...,\n",
       "            2.5646456e-02, 0.0000000e+00, 0.0000000e+00],\n",
       "           [5.0481975e-01, 1.9133843e-03, 9.1286772e-04, ...,\n",
       "            1.4227363e-02, 5.2386117e-03, 0.0000000e+00],\n",
       "           [7.8034478e-01, 1.2527069e-03, 3.6375920e-04, ...,\n",
       "            5.4688752e-03, 1.6910598e-03, 4.1517280e-03]]],\n",
       "  \n",
       "  \n",
       "         [[[1.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "            0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "           [2.4873051e-01, 7.5126946e-01, 0.0000000e+00, ...,\n",
       "            0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "           [1.4334485e-01, 2.8477019e-01, 5.7188493e-01, ...,\n",
       "            0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "           ...,\n",
       "           [1.8808482e-03, 9.1033790e-04, 2.9299778e-03, ...,\n",
       "            5.0718146e-03, 0.0000000e+00, 0.0000000e+00],\n",
       "           [2.4524319e-03, 7.3553273e-04, 2.4627016e-03, ...,\n",
       "            3.2035061e-03, 1.3328694e-02, 0.0000000e+00],\n",
       "           [2.9442932e-03, 8.6971279e-04, 3.1854487e-03, ...,\n",
       "            3.1494424e-03, 1.3545177e-02, 1.7739713e-02]],\n",
       "  \n",
       "          [[1.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "            0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "           [5.2299964e-01, 4.7700036e-01, 0.0000000e+00, ...,\n",
       "            0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "           [2.7575037e-01, 2.2928162e-01, 4.9496797e-01, ...,\n",
       "            0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "           ...,\n",
       "           [7.8310808e-03, 4.5193294e-03, 8.0880122e-03, ...,\n",
       "            3.2746140e-02, 0.0000000e+00, 0.0000000e+00],\n",
       "           [5.9692520e-03, 3.5508990e-03, 6.1422074e-03, ...,\n",
       "            3.1726066e-02, 3.6286283e-02, 0.0000000e+00],\n",
       "           [6.3254251e-03, 4.1282368e-03, 6.4207902e-03, ...,\n",
       "            2.5596917e-02, 2.6561471e-02, 2.5819052e-02]]]], dtype=float32)>,\n",
       "  'decoder_layer2': <tf.Tensor: shape=(64, 2, 80, 80), dtype=float32, numpy=\n",
       "  array([[[[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [7.87121654e-02, 9.21287894e-01, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [2.13291328e-02, 3.77247512e-01, 6.01423383e-01, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           ...,\n",
       "           [3.23292501e-02, 1.14412285e-01, 8.82249847e-02, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [6.73997700e-02, 1.16825454e-01, 7.64825344e-02, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [6.50641322e-02, 1.88593954e-01, 1.03758253e-01, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "  \n",
       "          [[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [9.53660667e-01, 4.63392995e-02, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [6.87523186e-01, 5.64022101e-02, 2.56074607e-01, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           ...,\n",
       "           [6.87523484e-02, 1.84291061e-02, 6.44598156e-02, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [5.06176278e-02, 2.02523079e-02, 7.16796592e-02, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [7.75579289e-02, 1.63264722e-02, 5.40746711e-02, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00]]],\n",
       "  \n",
       "  \n",
       "         [[[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [3.25369537e-01, 6.74630463e-01, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [2.47350037e-01, 1.66116059e-02, 7.36038327e-01, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           ...,\n",
       "           [2.00088974e-02, 9.40395799e-03, 2.23528091e-02, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [1.23067433e-02, 9.66270547e-03, 2.68398020e-02, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [3.89211737e-02, 3.71551607e-03, 3.53348441e-02, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "  \n",
       "          [[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [9.63995457e-02, 9.03600454e-01, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [9.34129000e-01, 7.13155046e-03, 5.87394983e-02, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           ...,\n",
       "           [5.49492659e-03, 1.73777764e-04, 2.49694823e-03, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [4.66020871e-03, 5.03314252e-04, 2.49950984e-03, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [7.11116102e-03, 1.03221515e-04, 1.99241494e-03, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00]]],\n",
       "  \n",
       "  \n",
       "         [[[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [7.32767880e-01, 2.67232120e-01, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [1.94825437e-02, 7.24246632e-03, 9.73274946e-01, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           ...,\n",
       "           [2.02426803e-03, 4.43603436e-04, 2.51756981e-03, ...,\n",
       "            8.79572630e-02, 0.00000000e+00, 0.00000000e+00],\n",
       "           [3.67610157e-03, 2.83477502e-03, 4.77618305e-03, ...,\n",
       "            2.69301739e-02, 1.28633408e-02, 0.00000000e+00],\n",
       "           [2.84084049e-03, 9.59269179e-04, 1.99720100e-03, ...,\n",
       "            3.84699069e-02, 1.36478906e-02, 9.80344601e-03]],\n",
       "  \n",
       "          [[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [9.40227568e-01, 5.97724542e-02, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [7.75273621e-01, 3.75117213e-02, 1.87214628e-01, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           ...,\n",
       "           [3.35366908e-03, 5.66218747e-04, 6.93582417e-03, ...,\n",
       "            2.27982793e-02, 0.00000000e+00, 0.00000000e+00],\n",
       "           [5.75619936e-03, 5.17799146e-03, 1.20180994e-02, ...,\n",
       "            6.79659192e-03, 1.10395895e-02, 0.00000000e+00],\n",
       "           [5.15011651e-03, 2.61659035e-03, 6.87494595e-03, ...,\n",
       "            1.43796774e-02, 8.88795871e-03, 1.35687059e-02]]],\n",
       "  \n",
       "  \n",
       "         ...,\n",
       "  \n",
       "  \n",
       "         [[[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [5.96042633e-01, 4.03957367e-01, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [2.09463671e-01, 3.43479156e-01, 4.47057188e-01, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           ...,\n",
       "           [9.74664057e-04, 1.52665516e-03, 9.33258794e-04, ...,\n",
       "            1.27190421e-03, 0.00000000e+00, 0.00000000e+00],\n",
       "           [1.39408326e-03, 2.77062668e-03, 1.90333382e-03, ...,\n",
       "            3.00061167e-03, 6.93149446e-03, 0.00000000e+00],\n",
       "           [3.03236023e-03, 3.22545599e-03, 1.99186429e-03, ...,\n",
       "            2.57536070e-03, 5.14916657e-03, 2.55900389e-03]],\n",
       "  \n",
       "          [[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [2.43182078e-01, 7.56817937e-01, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [3.97500731e-02, 6.22176945e-01, 3.38073015e-01, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           ...,\n",
       "           [5.86201844e-04, 1.36711886e-02, 6.02307077e-03, ...,\n",
       "            7.34135555e-03, 0.00000000e+00, 0.00000000e+00],\n",
       "           [8.69325770e-04, 5.17273024e-02, 1.99216381e-02, ...,\n",
       "            1.00333374e-02, 9.24072135e-03, 0.00000000e+00],\n",
       "           [1.90754700e-03, 6.95607951e-03, 3.66055453e-03, ...,\n",
       "            6.44942885e-03, 7.11730449e-03, 6.28501922e-03]]],\n",
       "  \n",
       "  \n",
       "         [[[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [8.43455076e-01, 1.56544849e-01, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [7.42034733e-01, 2.36279517e-02, 2.34337255e-01, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           ...,\n",
       "           [1.16796810e-02, 1.91315438e-03, 8.97308160e-03, ...,\n",
       "            1.35383778e-03, 0.00000000e+00, 0.00000000e+00],\n",
       "           [3.64348013e-03, 1.25381761e-04, 8.95863457e-04, ...,\n",
       "            1.92487671e-04, 3.45469173e-03, 0.00000000e+00],\n",
       "           [1.22636510e-02, 4.98826630e-05, 8.76167556e-04, ...,\n",
       "            5.36127300e-05, 4.60534915e-03, 1.52498866e-02]],\n",
       "  \n",
       "          [[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [5.12401700e-01, 4.87598270e-01, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [5.66489339e-01, 1.07383125e-01, 3.26127499e-01, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           ...,\n",
       "           [3.62465181e-03, 3.53573845e-03, 1.20656181e-03, ...,\n",
       "            4.81118681e-03, 0.00000000e+00, 0.00000000e+00],\n",
       "           [9.02487023e-04, 8.97562277e-05, 2.13791573e-04, ...,\n",
       "            9.38999292e-04, 8.43284710e-04, 0.00000000e+00],\n",
       "           [8.06985830e-04, 1.14918498e-06, 9.10459261e-04, ...,\n",
       "            2.18252811e-04, 9.38437972e-03, 4.23302455e-03]]],\n",
       "  \n",
       "  \n",
       "         [[[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [6.61846027e-02, 9.33815360e-01, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [2.75957002e-03, 1.66286398e-02, 9.80611742e-01, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           ...,\n",
       "           [2.05598226e-05, 3.19614037e-06, 3.70278955e-04, ...,\n",
       "            1.09262927e-03, 0.00000000e+00, 0.00000000e+00],\n",
       "           [6.47938668e-06, 2.97871054e-07, 2.05774222e-06, ...,\n",
       "            1.64869038e-04, 2.12755278e-02, 0.00000000e+00],\n",
       "           [4.63200149e-06, 3.07495156e-07, 1.60615048e-06, ...,\n",
       "            1.39053984e-04, 1.89795755e-02, 3.64320800e-02]],\n",
       "  \n",
       "          [[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [6.78168237e-01, 3.21831793e-01, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [1.54445246e-01, 1.53488964e-01, 6.92065775e-01, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           ...,\n",
       "           [2.94021564e-04, 1.30626967e-03, 9.12055373e-04, ...,\n",
       "            2.00399607e-02, 0.00000000e+00, 0.00000000e+00],\n",
       "           [1.60535579e-04, 6.42284402e-04, 6.13338343e-05, ...,\n",
       "            1.71250440e-02, 5.56158423e-02, 0.00000000e+00],\n",
       "           [1.86276695e-04, 6.35280157e-04, 7.96148306e-05, ...,\n",
       "            1.64502487e-02, 6.91065416e-02, 5.89693710e-02]]]],\n",
       "        dtype=float32)>,\n",
       "  'decoder_layer3': <tf.Tensor: shape=(64, 2, 80, 80), dtype=float32, numpy=\n",
       "  array([[[[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [5.52626014e-01, 4.47373927e-01, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [2.74160415e-01, 2.21872002e-01, 5.03967583e-01, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           ...,\n",
       "           [1.83202177e-02, 1.09227868e-02, 9.59888007e-03, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [5.88200847e-03, 3.85751179e-03, 3.85894463e-03, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [4.33017351e-02, 1.84914023e-02, 9.30462964e-03, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "  \n",
       "          [[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [4.06184316e-01, 5.93815684e-01, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [4.31246012e-01, 2.80174643e-01, 2.88579345e-01, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           ...,\n",
       "           [7.64136240e-02, 3.87192816e-02, 4.62156273e-02, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [8.25767517e-02, 3.19265537e-02, 3.20153162e-02, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [5.12937717e-02, 3.42250727e-02, 4.42025922e-02, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00]]],\n",
       "  \n",
       "  \n",
       "         [[[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [3.92802320e-02, 9.60719764e-01, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [4.50110435e-02, 7.50792146e-01, 2.04196781e-01, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           ...,\n",
       "           [4.76150634e-03, 8.36797431e-03, 4.13796958e-03, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [7.86186312e-04, 4.23803413e-03, 2.58194632e-03, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [5.01474412e-03, 6.10236824e-03, 4.12483932e-03, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "  \n",
       "          [[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [5.40784001e-01, 4.59215969e-01, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [5.43038808e-02, 2.81099737e-01, 6.64596319e-01, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           ...,\n",
       "           [6.09454047e-03, 2.84670689e-03, 9.81535017e-03, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [8.91462434e-03, 2.81233434e-03, 8.23659077e-03, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [2.79828161e-03, 2.22466351e-03, 8.61065462e-03, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00]]],\n",
       "  \n",
       "  \n",
       "         [[[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [7.27697968e-01, 2.72302061e-01, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [1.89992070e-01, 2.75496338e-02, 7.82458246e-01, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           ...,\n",
       "           [6.02671527e-04, 2.04093580e-04, 9.97510622e-04, ...,\n",
       "            2.82147024e-02, 0.00000000e+00, 0.00000000e+00],\n",
       "           [3.86318097e-05, 3.65002488e-05, 7.65691511e-05, ...,\n",
       "            9.14869364e-03, 3.04054352e-03, 0.00000000e+00],\n",
       "           [2.14040323e-04, 1.68856859e-04, 2.48465658e-04, ...,\n",
       "            2.17181500e-02, 2.92986678e-03, 3.73324333e-03]],\n",
       "  \n",
       "          [[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [8.16612422e-01, 1.83387592e-01, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [4.03099358e-01, 8.02741200e-02, 5.16626537e-01, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           ...,\n",
       "           [2.80778506e-03, 3.71680479e-04, 9.36606550e-04, ...,\n",
       "            2.48135552e-02, 0.00000000e+00, 0.00000000e+00],\n",
       "           [5.51864330e-04, 3.03288386e-03, 8.95450648e-04, ...,\n",
       "            1.21033147e-04, 2.22486269e-04, 0.00000000e+00],\n",
       "           [2.27383384e-03, 4.36706375e-03, 1.28057797e-03, ...,\n",
       "            5.77460683e-04, 5.28009259e-04, 1.56828167e-03]]],\n",
       "  \n",
       "  \n",
       "         ...,\n",
       "  \n",
       "  \n",
       "         [[[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [2.54249990e-01, 7.45750010e-01, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [3.02318215e-01, 4.84847128e-01, 2.12834656e-01, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           ...,\n",
       "           [8.94755794e-05, 1.03200335e-04, 7.83659343e-05, ...,\n",
       "            8.35275277e-04, 0.00000000e+00, 0.00000000e+00],\n",
       "           [5.45852599e-05, 6.77332719e-05, 4.98950649e-05, ...,\n",
       "            8.26367119e-04, 1.48727908e-03, 0.00000000e+00],\n",
       "           [9.74667855e-05, 9.03958644e-05, 6.15584431e-05, ...,\n",
       "            1.16503879e-03, 2.15685833e-03, 2.17924034e-03]],\n",
       "  \n",
       "          [[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [6.45376444e-01, 3.54623616e-01, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [7.37294912e-01, 1.67311057e-01, 9.53940302e-02, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           ...,\n",
       "           [2.86124237e-02, 3.54298321e-03, 2.62154243e-03, ...,\n",
       "            3.10869003e-03, 0.00000000e+00, 0.00000000e+00],\n",
       "           [1.64734107e-02, 4.19746106e-03, 3.82029777e-03, ...,\n",
       "            4.05846164e-03, 9.10501834e-03, 0.00000000e+00],\n",
       "           [2.36024596e-02, 1.68619363e-03, 1.51650596e-03, ...,\n",
       "            2.12963670e-03, 4.28008987e-03, 2.98440992e-03]]],\n",
       "  \n",
       "  \n",
       "         [[[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [5.45582831e-01, 4.54417199e-01, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [4.72844094e-01, 4.54073846e-01, 7.30819851e-02, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           ...,\n",
       "           [7.59215109e-05, 1.78057526e-04, 5.97115431e-05, ...,\n",
       "            2.64653866e-03, 0.00000000e+00, 0.00000000e+00],\n",
       "           [2.83435686e-03, 4.66529047e-03, 1.08724600e-03, ...,\n",
       "            4.99816053e-03, 3.59482528e-03, 0.00000000e+00],\n",
       "           [1.52990865e-02, 3.58057371e-03, 4.52371836e-02, ...,\n",
       "            3.33094969e-03, 1.92873105e-02, 4.57778340e-04]],\n",
       "  \n",
       "          [[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [8.65785897e-01, 1.34214073e-01, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [8.89090896e-01, 5.29169478e-02, 5.79920970e-02, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           ...,\n",
       "           [3.56086879e-03, 9.07972630e-04, 8.15373212e-02, ...,\n",
       "            2.62839370e-03, 0.00000000e+00, 0.00000000e+00],\n",
       "           [2.27324883e-04, 1.16310266e-05, 2.83761801e-06, ...,\n",
       "            5.82962857e-05, 5.71606415e-06, 0.00000000e+00],\n",
       "           [7.36499860e-05, 3.78820664e-06, 2.81964594e-06, ...,\n",
       "            2.02481442e-05, 1.06490797e-05, 4.89183376e-03]]],\n",
       "  \n",
       "  \n",
       "         [[[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [5.89264631e-01, 4.10735369e-01, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [1.05871424e-01, 7.28484988e-02, 8.21280062e-01, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           ...,\n",
       "           [2.73245765e-04, 2.76601728e-04, 5.19144302e-03, ...,\n",
       "            3.16615030e-03, 0.00000000e+00, 0.00000000e+00],\n",
       "           [1.75421446e-05, 3.00173233e-05, 4.87532583e-04, ...,\n",
       "            6.00244035e-04, 3.86510906e-03, 0.00000000e+00],\n",
       "           [2.91344859e-05, 4.91948667e-05, 6.67936052e-04, ...,\n",
       "            6.83930237e-04, 4.34077438e-03, 7.54952431e-03]],\n",
       "  \n",
       "          [[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [3.99547845e-01, 6.00452185e-01, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [1.62245259e-02, 3.58412415e-02, 9.47934210e-01, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           ...,\n",
       "           [7.55561457e-04, 7.91640719e-04, 4.34501609e-03, ...,\n",
       "            1.05801439e-02, 0.00000000e+00, 0.00000000e+00],\n",
       "           [3.95910675e-03, 6.40050799e-04, 1.47767219e-04, ...,\n",
       "            6.23029098e-03, 4.99609113e-02, 0.00000000e+00],\n",
       "           [8.31840001e-03, 6.29080110e-04, 5.13191262e-05, ...,\n",
       "            4.02760925e-03, 2.37656664e-02, 9.48334020e-03]]]],\n",
       "        dtype=float32)>,\n",
       "  'decoder_layer4': <tf.Tensor: shape=(64, 2, 80, 80), dtype=float32, numpy=\n",
       "  array([[[[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [6.81801021e-01, 3.18198949e-01, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [5.68049550e-01, 1.88671082e-01, 2.43279397e-01, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           ...,\n",
       "           [6.19024523e-02, 2.76484545e-02, 2.58827750e-02, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [4.76349443e-02, 2.17420254e-02, 1.94945373e-02, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [3.52319442e-02, 2.62097660e-02, 3.54464874e-02, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "  \n",
       "          [[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [5.83200514e-01, 4.16799486e-01, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [4.05635118e-01, 2.88217098e-01, 3.06147754e-01, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           ...,\n",
       "           [6.88979924e-02, 6.29489496e-02, 6.98819533e-02, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [5.00674322e-02, 5.80510572e-02, 5.45655899e-02, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [4.24962044e-02, 4.92478088e-02, 5.43267354e-02, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00]]],\n",
       "  \n",
       "  \n",
       "         [[[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [6.19479477e-01, 3.80520493e-01, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [9.69828069e-02, 2.97614396e-01, 6.05402827e-01, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           ...,\n",
       "           [1.74301304e-03, 1.42410921e-03, 9.75895673e-03, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [7.53628975e-03, 6.19027670e-03, 1.15108443e-02, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [7.24574202e-04, 9.05661669e-04, 7.42460182e-03, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "  \n",
       "          [[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [5.10165393e-01, 4.89834607e-01, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [6.44644380e-01, 8.64196718e-02, 2.68935889e-01, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           ...,\n",
       "           [1.25714783e-02, 2.98986607e-03, 8.08064919e-03, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [1.26332762e-02, 4.33097268e-03, 1.49588576e-02, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [6.73867017e-03, 1.39550515e-03, 6.30259048e-03, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00]]],\n",
       "  \n",
       "  \n",
       "         [[[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [8.35641980e-01, 1.64357975e-01, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [4.76802677e-01, 1.48037225e-01, 3.75160068e-01, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           ...,\n",
       "           [1.84017990e-04, 2.23377487e-04, 1.61517097e-03, ...,\n",
       "            1.36215473e-02, 0.00000000e+00, 0.00000000e+00],\n",
       "           [2.60114367e-03, 9.84035665e-04, 6.81633537e-05, ...,\n",
       "            4.69077859e-05, 6.35252986e-03, 0.00000000e+00],\n",
       "           [1.84725341e-03, 6.53901836e-04, 9.24801934e-05, ...,\n",
       "            5.72366989e-05, 2.36002319e-02, 1.09085692e-02]],\n",
       "  \n",
       "          [[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [7.04327583e-01, 2.95672387e-01, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [4.00267869e-01, 1.64095446e-01, 4.35636699e-01, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           ...,\n",
       "           [1.25833154e-02, 8.19293037e-03, 9.49790794e-03, ...,\n",
       "            8.12121388e-03, 0.00000000e+00, 0.00000000e+00],\n",
       "           [1.00344967e-03, 1.63648615e-03, 1.11253303e-03, ...,\n",
       "            1.32566388e-03, 9.06991679e-03, 0.00000000e+00],\n",
       "           [1.48759305e-03, 2.48468062e-03, 1.77702727e-03, ...,\n",
       "            1.30768446e-03, 3.75264771e-02, 2.39896197e-02]]],\n",
       "  \n",
       "  \n",
       "         ...,\n",
       "  \n",
       "  \n",
       "         [[[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [6.86713696e-01, 3.13286304e-01, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [8.25144649e-01, 9.17448327e-02, 8.31105188e-02, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           ...,\n",
       "           [1.27475953e-03, 2.22997987e-04, 2.21763999e-04, ...,\n",
       "            6.59994083e-04, 0.00000000e+00, 0.00000000e+00],\n",
       "           [9.27510089e-04, 1.37118943e-04, 1.36438801e-04, ...,\n",
       "            5.16741711e-04, 1.63594913e-03, 0.00000000e+00],\n",
       "           [1.35335268e-03, 4.40420408e-05, 4.28762360e-05, ...,\n",
       "            2.70613382e-04, 8.53606674e-04, 1.16677082e-03]],\n",
       "  \n",
       "          [[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [7.48310328e-01, 2.51689702e-01, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [6.21698558e-01, 1.57863274e-01, 2.20438182e-01, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           ...,\n",
       "           [1.07705882e-02, 4.24889335e-03, 5.35155367e-03, ...,\n",
       "            2.00497005e-02, 0.00000000e+00, 0.00000000e+00],\n",
       "           [8.87382030e-03, 5.68093220e-03, 6.74460782e-03, ...,\n",
       "            1.86060015e-02, 2.27163304e-02, 0.00000000e+00],\n",
       "           [7.30548846e-03, 3.62939178e-03, 4.47000796e-03, ...,\n",
       "            1.99795868e-02, 2.35110018e-02, 2.96958927e-02]]],\n",
       "  \n",
       "  \n",
       "         [[[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [9.56259847e-01, 4.37401459e-02, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [8.83821070e-01, 2.91722268e-03, 1.13261789e-01, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           ...,\n",
       "           [6.89449604e-04, 7.24383208e-05, 9.86928400e-03, ...,\n",
       "            1.75085885e-03, 0.00000000e+00, 0.00000000e+00],\n",
       "           [2.67352938e-04, 3.89790921e-06, 8.63921814e-05, ...,\n",
       "            1.72245946e-05, 1.77566346e-03, 0.00000000e+00],\n",
       "           [5.75518834e-06, 8.03977258e-08, 7.94321906e-08, ...,\n",
       "            3.95320470e-08, 2.42373085e-06, 3.39004444e-03]],\n",
       "  \n",
       "          [[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [6.75350189e-01, 3.24649781e-01, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [7.05930650e-01, 7.54388869e-02, 2.18630478e-01, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           ...,\n",
       "           [1.40661781e-04, 1.09039793e-04, 3.54621792e-04, ...,\n",
       "            1.43491779e-03, 0.00000000e+00, 0.00000000e+00],\n",
       "           [3.55365861e-04, 6.48753485e-05, 1.35696449e-04, ...,\n",
       "            1.64940939e-04, 1.67405105e-03, 0.00000000e+00],\n",
       "           [1.16167811e-03, 4.54894944e-05, 1.06116277e-04, ...,\n",
       "            3.36893536e-05, 9.21774888e-04, 7.28868274e-03]]],\n",
       "  \n",
       "  \n",
       "         [[[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [4.23367977e-01, 5.76632082e-01, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [2.46419311e-02, 4.74791005e-02, 9.27879035e-01, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           ...,\n",
       "           [1.00639285e-04, 6.90328088e-05, 1.92464550e-03, ...,\n",
       "            2.92596454e-03, 0.00000000e+00, 0.00000000e+00],\n",
       "           [7.82410905e-04, 8.47257907e-05, 4.42151359e-05, ...,\n",
       "            2.55702413e-04, 1.51935117e-02, 0.00000000e+00],\n",
       "           [1.11231906e-03, 7.88700418e-05, 1.51895765e-05, ...,\n",
       "            7.60589319e-05, 3.72703956e-03, 8.64134077e-03]],\n",
       "  \n",
       "          [[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [4.38357085e-01, 5.61642945e-01, 0.00000000e+00, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           [1.48279563e-01, 1.37178212e-01, 7.14542270e-01, ...,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "           ...,\n",
       "           [1.72280036e-02, 7.53382407e-03, 2.37778127e-02, ...,\n",
       "            4.50802827e-03, 0.00000000e+00, 0.00000000e+00],\n",
       "           [4.75612236e-03, 1.90647040e-03, 8.08861689e-04, ...,\n",
       "            2.99107371e-04, 1.36609247e-03, 0.00000000e+00],\n",
       "           [3.35394428e-03, 1.65098917e-03, 4.11142857e-04, ...,\n",
       "            2.45326723e-04, 8.51234188e-04, 2.10346095e-03]]]],\n",
       "        dtype=float32)>})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer(inp, tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_1 (Sequential)    (None, None, 128)         19968     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "decoder_1 (Decoder)          multiple                  398336    \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             multiple                  16512     \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             multiple                  2064      \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             multiple                  1015      \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             multiple                  1764      \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             multiple                  4619      \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             multiple                  4681      \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             multiple                  306       \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             multiple                  154       \n",
      "=================================================================\n",
      "Total params: 449,419\n",
      "Trainable params: 449,419\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transformer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (batch_no, (inp, tar)) in enumerate(train_batches):\n",
    "     with tf.GradientTape() as tape:\n",
    "        predictions, _ = transformer(inp, tar)\n",
    "        loss = train.loss_function(tar, predictions)\n",
    "        gradients = tape.gradient(loss, self.transformer.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, self.transformer.trainable_variables))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "Epoch 1 Batch0 Loss 8.9938\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "Epoch 1 Batch50 Loss 7.7156\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "Epoch 1 Batch100 Loss 7.6277\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer/dense_33/kernel:0', 'transformer/dense_33/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_819226/3643264482.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m  \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/gpu:1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/pythonproject/Thesis/synthetic/Transformer/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_batches, val_batches, epochs, early_stop)\u001b[0m\n\u001b[1;32m    243\u001b[0m                     \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m                 \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mainenv/lib/python3.7/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1086\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mainenv/lib/python3.7/site-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/mainenv/lib/python3.7/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    160\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mainenv/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_MeanGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_MeanGrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m   \u001b[0;34m\"\"\"Gradient for Mean.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m   \u001b[0msum_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_SumGrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m   \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m   \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mainenv/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_SumGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtile_scaling\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m   \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"keep_dims\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mainenv/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mainenv/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mshape\u001b[0;34m(input, name, out_type)\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m   \"\"\"\n\u001b[0;32m--> 649\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mshape_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mainenv/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mshape_internal\u001b[0;34m(input, name, optimize, out_type)\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moptimize\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_fully_defined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mainenv/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mshape\u001b[0;34m(input, out_type, name)\u001b[0m\n\u001b[1;32m   9156\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9157\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m-> 9158\u001b[0;31m         _ctx, \"Shape\", name, input, \"out_type\", out_type)\n\u001b[0m\u001b[1;32m   9159\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9160\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "early_stop = 2\n",
    "train = Train(transformer)\n",
    "with  tf.device('/gpu:1'):\n",
    "    train.train(train_batches, val_batches, epochs, early_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential (Sequential)      (None, None, 128)         19968     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "decoder (Decoder)            multiple                  398336    \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             multiple                  16512     \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             multiple                  2064      \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             multiple                  1015      \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             multiple                  1764      \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             multiple                  4619      \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             multiple                  4681      \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             multiple                  306       \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             multiple                  154       \n",
      "=================================================================\n",
      "Total params: 449,419\n",
      "Trainable params: 449,419\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transformer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch0 Loss 21.4667\n",
      "Epoch 1 Batch50 Loss 7.6651\n",
      "Epoch 1 Batch100 Loss 6.2767\n",
      "Epoch 1 Batch150 Loss 5.6429\n",
      "Epoch 1 Loss 5.3902\n",
      "** on validation data loss is 3.9468\n",
      "Time taken for 1 epoch: 12.34 secs\n",
      "\n",
      "Epoch 2 Batch0 Loss 3.9213\n",
      "Epoch 2 Batch50 Loss 3.7799\n",
      "Epoch 2 Batch100 Loss 3.6469\n",
      "Epoch 2 Batch150 Loss 3.5157\n",
      "Epoch 2 Loss 3.4545\n",
      "** on validation data loss is 3.0823\n",
      "Time taken for 1 epoch: 14.31 secs\n",
      "\n",
      "Epoch 3 Batch0 Loss 3.2131\n",
      "Epoch 3 Batch50 Loss 2.9771\n",
      "Epoch 3 Batch100 Loss 2.8854\n",
      "Epoch 3 Batch150 Loss 2.8231\n",
      "Epoch 3 Loss 2.7871\n",
      "** on validation data loss is 2.6088\n",
      "Time taken for 1 epoch: 12.55 secs\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from lib.field_info import FieldInfo\n",
    "fieldInfo = FieldInfo(n_tcodes)\n",
    "\n",
    "\n",
    "loss_scce_logit = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "loss_mse = tf.keras.losses.MeanSquaredError(reduction='none')\n",
    "\n",
    "LOSS_WEIGHTS = {\n",
    " 'td_sc':1.,\n",
    " 'month': 0.015,\n",
    " 'day': 0.025,\n",
    " 'dtme': 0.025,\n",
    " 'dow': 0.01,\n",
    " 'tcode_num': 1.,\n",
    " 'log_amount_sc': 2.}\n",
    "\n",
    "FIELD_STARTS_TAR = fieldInfo.FIELD_STARTS_TAR\n",
    "FIELD_DIMS_TAR = fieldInfo.FIELD_DIMS_TAR\n",
    "LOSS_TYPES = fieldInfo.LOSS_TYPES\n",
    "\n",
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "    log2pi = tf.math.log(2. * np.pi)\n",
    "    return  -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi)\n",
    "\n",
    "\n",
    "def loss_function(real, preds):\n",
    "    loss_parts = []\n",
    "    loss_parts_weighted = []\n",
    "    mask = tf.math.logical_not(tf.math.equal(tf.reduce_sum(real, axis=2), 0))\n",
    "    for k, k_pred in preds.items():\n",
    "        st = FIELD_STARTS_TAR[k]\n",
    "        end = st + FIELD_DIMS_TAR[k]\n",
    "        loss_type = LOSS_TYPES[k]\n",
    "        if loss_type == \"scce\":\n",
    "           loss_ = loss_scce_logit(real[:, :, st:end], k_pred)\n",
    "        elif loss_type == \"pdf\":\n",
    "           temp = -log_normal_pdf(real[:, :, st:end], k_pred[:,:,0:1], k_pred[:,:,1:2])\n",
    "           loss_ = -log_normal_pdf(real[:, :, st:end], k_pred[:,:,0:1], k_pred[:,:,1:2])[:,:,0]\n",
    "        elif loss_type == 'mse':\n",
    "           loss_ = loss_mse(real[:, :, st:end], k_pred)\n",
    "        \n",
    "        mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "        loss_ *= mask\n",
    "        loss_ = tf.reduce_sum(loss_)/tf.reduce_sum(mask) \n",
    "\n",
    "        loss_parts.append(loss_)\n",
    "        loss_parts_weighted.append(loss_ * LOSS_WEIGHTS[k])\n",
    "    return tf.reduce_sum(loss_parts_weighted)\n",
    "\n",
    "class Train(object):\n",
    "    def __init__(self, transformer):\n",
    "        self.transformer = transformer\n",
    "        self.train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "        self.validation_loss = tf.keras.metrics.Mean(name='val_loss')\n",
    "        self.results = dict([(x, []) for x in [\"loss\", \"val_loss\"]])\n",
    "\n",
    "    def train(self, train_batches, x_cv, targ_cv, epochs, early_stop):\n",
    "        optimizer = tf.keras.optimizers.Adam() \n",
    "        for epoch in range(epochs):\n",
    "            start = time.time()\n",
    "            self.train_loss.reset_states()\n",
    "            self.validation_loss.reset_states()\n",
    "            for (batch_no, (inp, tar)) in enumerate(train_batches):\n",
    "                with tf.GradientTape() as tape:\n",
    "                    predictions, _ = transformer(inp, tar)\n",
    "                    loss = loss_function(tar, predictions)\n",
    "                gradients = tape.gradient(loss, transformer.trainable_variables)\n",
    "                optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "               \n",
    "                self.train_loss(loss)\n",
    "                if batch_no % 50 == 0:\n",
    "                    print(f'Epoch {epoch+1} Batch{batch_no} Loss{self.train_loss.result(): .4f}')\n",
    "            print(f'Epoch {epoch + 1} Loss {self.train_loss.result():.4f}')\n",
    "            for (_, (x_cv, targ_cv)) in enumerate(val_batches):\n",
    "                predictions_val, _ = transformer(x_cv, targ_cv)\n",
    "                loss_v = loss_function(targ_cv, predictions_val)\n",
    "                self.validation_loss(loss_v)\n",
    "            print(f\"** on validation data loss is {self.validation_loss.result():.4f}\")\n",
    "            self.results[\"loss\"].append(self.train_loss.result().numpy())\n",
    "            self.results[\"val_loss\"].append(self.validation_loss.result().numpy())\n",
    "            \n",
    "            print(f'Time taken for 1 epoch: {time.time() - start:.2f} secs\\n')\n",
    "            \n",
    "            if min(self.results[\"val_loss\"] ) < min(self.results[\"val_loss\"][-early_stop:] ):\n",
    "                \n",
    "                print(f\"Stopping early, last {early_stop} val losses are: {self.results['val_loss'][-early_stop:]} \\\n",
    "                      \\nBest was {min(self.results['val_loss'] ):.3f}\\n\\n\")\n",
    "                break\n",
    "        \n",
    "import tensorflow as tf\n",
    "from lib.modules import Transformer\n",
    "import time\n",
    "\n",
    "ACTIVATIONS = {\n",
    "    \"td_sc\": \"relu\",\n",
    "    \"log_amount_sc\": \"relu\"\n",
    "}\n",
    "fieldInfo = FieldInfo(n_tcodes)\n",
    "config = {}\n",
    "config[\"ORDER\"] = fieldInfo.DATA_KEY_ORDER\n",
    "config[\"FIELD_STARTS_IN\"] = fieldInfo.FIELD_STARTS_IN\n",
    "config[\"FIELD_DIMS_IN\"] = fieldInfo.FIELD_DIMS_IN\n",
    "config[\"FIELD_STARTS_NET\"] = fieldInfo.FIELD_STARTS_NET\n",
    "config[\"FIELD_DIMS_NET\"] = fieldInfo.FIELD_DIMS_NET\n",
    "config[\"ACTIVATIONS\"] = ACTIVATIONS\n",
    "\n",
    "n_seqs, seq_len, features = encoder.inp_tensor.shape\n",
    "#features = 26\n",
    "d_embedding = 128\n",
    "dff = 128\n",
    "d_model = 128\n",
    "batch_size = 64\n",
    "seq_len = 80\n",
    "maximum_position_encoding = 256\n",
    "rate = 0.1\n",
    "num_heads = 2\n",
    "num_layers = 4\n",
    "raw_features = 7\n",
    "transformer = Transformer(features,dff, d_embedding, d_model, maximum_position_encoding,num_heads, num_layers,config, rate=0.1)\n",
    "epochs = 3\n",
    "early_stop = 2\n",
    "train = Train(transformer)\n",
    "with  tf.device('/gpu:1'):\n",
    "    train.train(train_batches,x_cv, targ_cv, epochs, early_stop)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<modules.Transformer at 0x7f5d0c165a90>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('1993-01-01 00:00:00')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "START_DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14354,)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 894 1012  549]\n",
      "[ 894 1019  555]\n",
      "[ 905 1077  555]\n",
      "[ 910 1136  559]\n",
      "[ 910 1200  573]\n",
      "[ 919 1238  576]\n",
      "[ 922 1297  576]\n",
      "[ 928 1325  581]\n",
      "[ 935 1326  582]\n",
      "[ 941 1338  585]\n",
      "[ 941 1381  588]\n",
      "[ 949 1473  603]\n",
      "[ 959 1537  607]\n",
      "[ 966 1563  607]\n",
      "[ 966 1567  607]\n",
      "[ 972 1573  607]\n",
      "[ 972 1580  608]\n",
      "[ 983 1676  612]\n",
      "[ 990 1749  614]\n",
      "[ 994 1778  616]\n",
      "[1002 1870  620]\n",
      "[1002 1929  637]\n",
      "[1015 1992  637]\n",
      "[1016 2022  639]\n",
      "[1022 2082  642]\n",
      "[1023 2111  643]\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import calendar\n",
    "from modules import create_masks\n",
    "\n",
    "max_length = 25\n",
    "MAX_YEARS_SPAN = 15\n",
    "get_dtme = lambda d: calendar.monthrange(d.year, d.month)[1] - d.day\n",
    "\n",
    "END_DATE = START_DATE.replace(year = START_DATE.year+ MAX_YEARS_SPAN)\n",
    "\n",
    "ALL_DATES = [START_DATE + datetime.timedelta(i) for i in range((END_DATE - START_DATE).days)]\n",
    "\n",
    "AD = np.array([(d.month % 12, d.day % 31, d.weekday() % 7, i, d.year, get_dtme(d)) for i, d in enumerate(ALL_DATES)])\n",
    "\n",
    "start_date_opts = df.groupby(\"account_id\")[\"datetime\"].min().dt.date.to_list()   #len = 4500\n",
    "n_seqs_to_generate = 3\n",
    "start_dates = np.random.choice(start_date_opts, size=n_seqs_to_generate) # sample start dates from real data\n",
    "\n",
    "attributes = encoder.attributes\n",
    "seq_ages = np.random.choice(attributes, size=n_seqs_to_generate) # sample ages from real data\n",
    "\n",
    "#generate sequences\n",
    "start_inds = np.array([(d - START_DATE.date()).days for d in start_dates])    #array([1284,  201])\n",
    "print(start_inds)\n",
    "inp = np.repeat(np.array(seq_ages)[:, None, None], repeats=n_feat_inp, axis=2) / ATTR_SCALE   #(n_seqs_to_generate, 1, n_feat_inp) \n",
    "raw_date_info_list = []\n",
    "for i in range(max_length):\n",
    "    predictions, attn, raw_ps, date_inds, enc_preds, raw_date  = call_to_generate(transformer, inp, start_inds)\n",
    "    print(date_inds)\n",
    "    enc_preds = tf.reshape(tf.constant(enc_preds), shape=(-1,1, n_feat_inp))      #(n_seqs_to_generate, 1, n_feat_inp=26)\n",
    "    inp = tf.concat([inp, enc_preds], axis=1)   \n",
    "    raw_date_info_list.append(raw_date)  \n",
    "    start_inds = date_inds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'month': array([ 6, 10,  7]),\n",
       "  'day': array([14, 17, 10]),\n",
       "  'year': array([1995, 1995, 1994])},\n",
       " {'month': array([6, 0, 7]),\n",
       "  'day': array([25, 14, 10]),\n",
       "  'year': array([1995, 1995, 1994])},\n",
       " {'month': array([6, 2, 7]),\n",
       "  'day': array([30, 11, 14]),\n",
       "  'year': array([1995, 1996, 1994])},\n",
       " {'month': array([6, 4, 7]),\n",
       "  'day': array([30, 15, 28]),\n",
       "  'year': array([1995, 1996, 1994])},\n",
       " {'month': array([7, 5, 7]),\n",
       "  'day': array([ 9, 23,  0]),\n",
       "  'year': array([1995, 1996, 1994])},\n",
       " {'month': array([7, 7, 7]),\n",
       "  'day': array([12, 21,  0]),\n",
       "  'year': array([1995, 1996, 1994])},\n",
       " {'month': array([7, 8, 8]),\n",
       "  'day': array([18, 18,  5]),\n",
       "  'year': array([1995, 1996, 1994])},\n",
       " {'month': array([7, 8, 8]),\n",
       "  'day': array([25, 19,  6]),\n",
       "  'year': array([1995, 1996, 1994])},\n",
       " {'month': array([7, 8, 8]),\n",
       "  'day': array([0, 0, 9]),\n",
       "  'year': array([1995, 1996, 1994])},\n",
       " {'month': array([ 7, 10,  8]),\n",
       "  'day': array([ 0, 13, 12]),\n",
       "  'year': array([1995, 1996, 1994])},\n",
       " {'month': array([8, 1, 8]),\n",
       "  'day': array([ 8, 13, 27]),\n",
       "  'year': array([1995, 1997, 1994])},\n",
       " {'month': array([8, 3, 8]),\n",
       "  'day': array([18, 18,  0]),\n",
       "  'year': array([1995, 1997, 1994])},\n",
       " {'month': array([8, 4, 8]),\n",
       "  'day': array([25, 13,  0]),\n",
       "  'year': array([1995, 1997, 1994])},\n",
       " {'month': array([8, 4, 8]),\n",
       "  'day': array([25, 17,  0]),\n",
       "  'year': array([1995, 1997, 1994])},\n",
       " {'month': array([8, 4, 8]),\n",
       "  'day': array([ 0, 23,  0]),\n",
       "  'year': array([1995, 1997, 1994])},\n",
       " {'month': array([8, 4, 9]),\n",
       "  'day': array([ 0, 30,  1]),\n",
       "  'year': array([1995, 1997, 1994])},\n",
       " {'month': array([9, 8, 9]),\n",
       "  'day': array([11,  4,  5]),\n",
       "  'year': array([1995, 1997, 1994])},\n",
       " {'month': array([ 9, 10,  9]),\n",
       "  'day': array([18, 16,  7]),\n",
       "  'year': array([1995, 1997, 1994])},\n",
       " {'month': array([ 9, 11,  9]),\n",
       "  'day': array([22, 14,  9]),\n",
       "  'year': array([1995, 1997, 1994])},\n",
       " {'month': array([9, 2, 9]),\n",
       "  'day': array([30, 14, 13]),\n",
       "  'year': array([1995, 1998, 1994])},\n",
       " {'month': array([9, 4, 9]),\n",
       "  'day': array([30, 14, 30]),\n",
       "  'year': array([1995, 1998, 1994])},\n",
       " {'month': array([10,  6,  9]),\n",
       "  'day': array([13, 16, 30]),\n",
       "  'year': array([1995, 1998, 1994])},\n",
       " {'month': array([10,  7, 10]),\n",
       "  'day': array([14, 16,  2]),\n",
       "  'year': array([1995, 1998, 1994])},\n",
       " {'month': array([10,  9, 10]),\n",
       "  'day': array([20, 14,  5]),\n",
       "  'year': array([1995, 1998, 1994])},\n",
       " {'month': array([10, 10, 10]),\n",
       "  'day': array([21, 13,  6]),\n",
       "  'year': array([1995, 1998, 1994])}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_date_info_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data generated by BF back to the original data space\n",
    "seqs = inp\n",
    "ages = seqs[:, 0, :] * ATTR_SCALE\n",
    "seqs = seqs[:, 1:, :]\n",
    "np.diff(ages)\n",
    "assert np.sum(np.diff(ages)) == 0, f\"Bad formating, expected all entries same in each row, got {ages}\"\n",
    "FIELD_STARTS_IN = transformer.FIELD_STARTS_IN\n",
    "FIELD_DIMS_IN = transformer.FIELD_DIMS_IN\n",
    "amts = seqs[:, :, FIELD_STARTS_IN[\"log_amount_sc\"]].numpy() * LOG_AMOUNT_SCALE\n",
    "amts = 10 ** amts\n",
    "amts = np.round(amts - 1.0, 2)\n",
    "days_passed = np.round(seqs[:, :, FIELD_STARTS_IN[\"td_sc\"]] * TD_SCALE ).astype(int)\n",
    "t_code = np.argmax(seqs[:, :, FIELD_STARTS_IN[\"tcode_num\"]: FIELD_STARTS_IN[\"tcode_num\"] + FIELD_DIMS_IN[\"tcode_num\"]], axis=-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Flatten arrays and translate transaction codes\n",
    "flattened_amts = amts.flatten()\n",
    "flattened_tcodes = t_code.flatten()\n",
    "translated_tcodes = [NUM_TO_TCODE[code] for code in flattened_tcodes]\n",
    "\n",
    "# Create DataFrame for amounts and transaction codes\n",
    "df_synth = pd.DataFrame({\n",
    "    'amount': flattened_amts,\n",
    "    'transaction_code': translated_tcodes\n",
    "})\n",
    "\n",
    "# Handling account IDs\n",
    "num_customers = amts.shape[0]\n",
    "num_transactions = amts.shape[1]\n",
    "account_ids = np.repeat(range(num_customers), num_transactions)\n",
    "df_synth['account_id'] = account_ids\n",
    "\n",
    "# Handling date information\n",
    "months = []\n",
    "days = []\n",
    "years = []\n",
    "\n",
    "for customer in range(num_customers):\n",
    "    for transaction in range(num_transactions):\n",
    "        months.append(raw_date_info_list[transaction]['month'][customer])\n",
    "        days.append(raw_date_info_list[transaction]['day'][customer])\n",
    "        years.append(raw_date_info_list[transaction]['year'][customer])\n",
    "\n",
    "# Converting lists to numpy arrays\n",
    "months = np.array(months)\n",
    "days = np.array(days)\n",
    "years = np.array(years)\n",
    "\n",
    "# Function to substitute month 0 with 12 and adjust days based on the month\n",
    "def adjust_month_and_day(month, day):\n",
    "    # Substitute month 0 with 12\n",
    "    month = 12 if month == 0 else month\n",
    "\n",
    "    # Adjust the day based on the month\n",
    "    # Months with 31 days\n",
    "    if month in [1, 3, 5, 7, 8, 10, 12]:\n",
    "        return month, 31 if day == 0 else day\n",
    "    # February (not considering leap years in this example)\n",
    "    elif month == 2:\n",
    "        return month, 28 if day == 0 else day\n",
    "    # Months with 30 days\n",
    "    else:\n",
    "        return month, 30 if day == 0 else day\n",
    "\n",
    "# Applying the adjustments to months and days\n",
    "adjusted_months, adjusted_days = zip(*[adjust_month_and_day(m, d) for m, d in zip(months, days)])\n",
    "\n",
    "# Converting to numpy arrays\n",
    "adjusted_months = np.array(adjusted_months)\n",
    "adjusted_days = np.array(adjusted_days)\n",
    "\n",
    "\n",
    "df_synth['year'] = years\n",
    "df_synth['month'] = adjusted_months\n",
    "df_synth['day'] = adjusted_days\n",
    "\n",
    "df_synth['date'] = pd.to_datetime(df_synth[['year', 'month', 'day']])\n",
    "\n",
    "# Handling days passed\n",
    "flattened_days_passed = days_passed.flatten()\n",
    "flattened_days_passed[::num_transactions] = 0  # Setting the first transaction's days_passed to 0\n",
    "df_synth['days_passed'] = flattened_days_passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 80)\n",
    "df_synth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount</th>\n",
       "      <th>transaction_code</th>\n",
       "      <th>account_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>164.610001</td>\n",
       "      <td>DEBIT__CASH WITHDRAWAL__PAYMENT ON STATEMENT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>104.949997</td>\n",
       "      <td>DEBIT__CASH WITHDRAWAL__</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99.790001</td>\n",
       "      <td>CREDIT__nan__INTEREST CREDITED</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.600000</td>\n",
       "      <td>DEBIT__CASH WITHDRAWAL__PAYMENT ON STATEMENT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016.709961</td>\n",
       "      <td>CREDIT__COLLECTION FROM ANOTHER BANK__nan</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>157.119995</td>\n",
       "      <td>DEBIT__CASH WITHDRAWAL__PAYMENT ON STATEMENT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>36.750000</td>\n",
       "      <td>CREDIT__nan__INTEREST CREDITED</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2632.419922</td>\n",
       "      <td>DEBIT__CREDIT CARD WITHDRAWAL__nan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1330.160034</td>\n",
       "      <td>DEBIT__REMITTANCE TO ANOTHER BANK__</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2438.379883</td>\n",
       "      <td>CREDIT__CREDIT IN CASH__nan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        amount                              transaction_code  account_id\n",
       "0   164.610001  DEBIT__CASH WITHDRAWAL__PAYMENT ON STATEMENT           0\n",
       "1   104.949997                     DEBIT__CASH WITHDRAWAL__            0\n",
       "2    99.790001                CREDIT__nan__INTEREST CREDITED           0\n",
       "3    14.600000  DEBIT__CASH WITHDRAWAL__PAYMENT ON STATEMENT           0\n",
       "4  2016.709961     CREDIT__COLLECTION FROM ANOTHER BANK__nan           0\n",
       "5   157.119995  DEBIT__CASH WITHDRAWAL__PAYMENT ON STATEMENT           1\n",
       "6    36.750000                CREDIT__nan__INTEREST CREDITED           1\n",
       "7  2632.419922            DEBIT__CREDIT CARD WITHDRAWAL__nan           1\n",
       "8  1330.160034          DEBIT__REMITTANCE TO ANOTHER BANK__            1\n",
       "9  2438.379883                   CREDIT__CREDIT IN CASH__nan           1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 3, 2, 4, 3],\n",
       "       [3, 2, 3, 0, 3]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5, 12,  6,  0,  5],\n",
       "       [ 1,  4,  4,  2,  4]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "days_passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 115.5 ,  114.69,   29.51,   17.83, 1439.09],\n",
       "       [ 175.79,   55.53, 1083.36, 1482.6 , 1261.26]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tcode_num': 0,\n",
       " 'dow': 16,\n",
       " 'month': 18,\n",
       " 'day': 20,\n",
       " 'dtme': 22,\n",
       " 'td_sc': 24,\n",
       " 'log_amount_sc': 25}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FIELD_STARTS_IN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 115.5 ,  114.69,   29.51,   17.83, 1439.09],\n",
       "       [ 175.79,   55.53, 1083.36, 1482.6 , 1261.26]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_normal_pdf_gen(sample, mean, logvar, raxis=1):\n",
    "    log2pi = tf.cast(tf.math.log(2. * np.pi), tf.float64)\n",
    "    return  -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi)\n",
    "\n",
    "def raw_dates_to_reencoded(raw_preds, start_inds,  max_days = 100, greedy_decode=False):\n",
    "\n",
    "    \"\"\" Takes raw predictions (info about predicted day, month, dow, and days passed) and start inds (indicate the current date for each of the seqs) \n",
    "        Computes a number of days passed for each based on inputs (either greedily or with sampling)\n",
    "         returns the new_dates (old_dates + days passed) and their indicies   \"\"\"\n",
    "    # raw_preds[k][:, -1]-- get the last element in each sequence  \n",
    "    all_ps = [tf.nn.softmax(raw_preds[k][:,-1]).numpy() for k in [\"month\", \"day\", \"dow\", \"dtme\"]]  #length of list: 4\n",
    "    timesteps = np.zeros(len(start_inds)).astype(int)\n",
    "    for i, (month_ps, day_ps, dow_ps, dtme_ps, td_pred, si) in enumerate(zip(*all_ps, raw_preds[\"td_sc\"][:,-1].numpy(), start_inds)):\n",
    "            \n",
    "        ps = month_ps[AD[si:si+max_days,0]]*day_ps[AD[si:si+max_days,1]]*dow_ps[AD[si:si+max_days,2]] *dtme_ps[AD[si:si+max_days,-1]] * \\\n",
    "                    np.exp(log_normal_pdf_gen(AD[si:si+max_days,3]-si, mean = td_pred[0]*TD_SCALE, logvar=td_pred[1]*TD_SCALE))  #shape(max_days,)\n",
    "\n",
    "            \n",
    "        if greedy_decode:\n",
    "            timesteps[i] = np.argmax(ps)\n",
    "        else:\n",
    "            timesteps[i] = np.random.choice(max_days, p=ps/sum(ps))\n",
    "    inds = start_inds + timesteps\n",
    "        \n",
    "        \n",
    "    return_ = {}\n",
    "    return_[\"td_sc\"] = tf.expand_dims(timesteps.astype(np.float32)/ TD_SCALE, axis=1)\n",
    "    return_[\"month\"] = bulk_encode_time_value(AD[inds, 0], 12)\n",
    "    return_[\"day\"] = bulk_encode_time_value(AD[inds, 1], 31)\n",
    "    return_[\"dow\"] = bulk_encode_time_value(AD[inds, 2], 7)\n",
    "    return_[\"dtme\"] = bulk_encode_time_value(AD[inds, -1], 31)\n",
    "\n",
    "    raw_date = {}\n",
    "    raw_date['month'] = AD[inds, 0]\n",
    "    raw_date['day'] = AD[inds, 1]\n",
    "    raw_date['year'] = AD[inds, 4]\n",
    "\n",
    "    return return_, inds, raw_date\n",
    "\n",
    "\n",
    "def bulk_encode_time_value(val, max_val):\n",
    "        \"\"\" encoding date features in the clockwise dimension \"\"\"\n",
    "        x = np.sin(2 * np.pi / max_val * val)\n",
    "        y = np.cos(2 * np.pi / max_val * val)\n",
    "        return np.stack([x, y], axis=1)\n",
    "\n",
    "\n",
    "def reencode_net_prediction(net_name, predictions):\n",
    "    \"\"\"net_name is in ['tcode_num', 'dow', 'month', 'day', 'dtme', 'td_sc', 'log_amount_sc']\n",
    "       predictions is the predicted feature (feature=net_name) \n",
    "       function:  transform predictions to the correct form to be used as input to BF\n",
    "       the transformed predictions also are used for conditional generating\n",
    "                \n",
    "    \"\"\"\n",
    "    date_info = {'month':12, 'day':31, 'dtme':31, 'dow':7}\n",
    "    batch_size = predictions.shape[0]\n",
    "    if \"_num\" in net_name:\n",
    "        dim = transformer.FIELD_DIMS_NET[net_name]\n",
    "        choices = np.arange(dim)\n",
    "        ps = tf.nn.softmax(predictions, axis=2).numpy().reshape(-1, dim)    #predictions: (n_seq_to_generate, seq_len, dim=16)\n",
    "        choosen =  np.reshape([np.random.choice(choices, p=p) for p in ps], newshape=(batch_size, -1))\n",
    "\n",
    "        return tf.one_hot(choosen, depth=dim)      #(n_seq_to_generate, seq_len, dim=16)\n",
    "\n",
    "    elif net_name in date_info.keys():\n",
    "        dim = transformer.FIELD_DIMS_NET[net_name]\n",
    "        choices = np.arange(dim)\n",
    "        ps = tf.nn.softmax(predictions, axis=2).numpy().reshape(-1, dim)\n",
    "        choosen =  np.array([np.random.choice(choices, p=p) for p in ps])\n",
    "        \n",
    "        x = bulk_encode_time_value(choosen, max_val=dim)\n",
    "        \n",
    "        return np.reshape(x, newshape=(batch_size, -1, 2))\n",
    "\n",
    "    elif net_name in ['td_sc', \"log_amount_sc\"]:\n",
    "        return predictions[:, :, 0:1]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ListWrapper(['tcode_num', 'dow', 'month', 'day', 'dtme', 'td_sc', 'log_amount_sc'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.ORDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_to_generate(transformer, inp, start_inds):\n",
    "    \"\"\"Forward pass through transformer\n",
    "    Returns: preds, attn_w, raw_preds, inds\n",
    "    the returned preds have multiple timesteps, but we only care about the last (it's the only new one)   \"\"\"\n",
    "\n",
    "    x = transformer.input_layer(inp)\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    x += transformer.pos_encoding[:, :seq_len, :]     #x is the output of Input layer\n",
    "    x = transformer.dropout(x, training=True)\n",
    "    mask, _ = create_masks(inp)\n",
    "    out, attention_weights = transformer.DecoderStack(x, True, mask)\n",
    "    final_output = transformer.final_layer(out)\n",
    "\n",
    "    ### Predict each field  ###\n",
    "    preds = {}\n",
    "    raw_preds = {}\n",
    "    encoded_preds_d = {}\n",
    "    #encoded_preds = []\n",
    "\n",
    "    for net_name in transformer.ORDER:  \n",
    "        pred = transformer.__getattribute__(net_name)(final_output)\n",
    "        raw_preds[net_name] = pred\n",
    "\n",
    "        pred = reencode_net_prediction(net_name, pred) \n",
    "        preds[net_name] = pred\n",
    "            \n",
    "        encoded_preds_d[net_name] = pred[:,-1,:] \n",
    "        #encoded_preds.append(pred[:,-1,:])\n",
    "        final_output = tf.concat([final_output, pred], axis=2)\n",
    "\n",
    "    date_info, inds, raw_date_info = raw_dates_to_reencoded(raw_preds, start_inds)\n",
    "    \n",
    "    encoded_preds_d.update(date_info)\n",
    "    l = [encoded_preds_d[k] for k in transformer.ORDER]\n",
    "    encoded_preds =  tf.expand_dims(tf.concat(l, axis=1), axis=1)   #tensor of shape (n_seqs_to_generate, 1, 26(input features))\n",
    "\n",
    "    return preds, attention_weights, raw_preds, inds, encoded_preds, raw_date_info\n",
    "    \n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1, 16), dtype=float32, numpy=\n",
       "array([[[ 2.606456  ,  1.9652989 ,  1.0356619 ,  1.6328188 ,\n",
       "          1.0518488 ,  0.50476277, -2.082876  ,  0.17730191,\n",
       "          0.9945889 , -6.3227634 , -0.73363006, -0.05845775,\n",
       "         -2.3763046 , -2.1853278 , -3.2781813 , -2.904684  ]],\n",
       "\n",
       "       [[ 2.3194718 ,  0.90071404,  0.9927165 ,  1.6883271 ,\n",
       "          0.52983195,  0.76463836, -2.58171   ,  0.20744765,\n",
       "          0.96543586, -5.3389544 , -1.4356111 ,  0.04906608,\n",
       "         -2.498517  , -2.2893934 , -3.8080366 , -3.7633495 ]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1, 16), dtype=float32, numpy=\n",
       "array([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reencode_net_prediction('tcode_num', pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1284,  201])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('1993-01-01 00:00:00')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "START_DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(self, generatedseq_len, START_DATE,ATTR_SCALE,df, n_seqs_to_generate, attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from modules import InputEmbedLayer,InputEmbedLayer_Res, ResidualLayer, RandomNoise_Simulator_Normal, positional_encoding, MultiHeadAttention, create_masks, DecoderLayer\n",
    "# import tensorflow as tf\n",
    "# features = 26\n",
    "# d_embedding = 128\n",
    "# dff = 128\n",
    "# d_model = 128\n",
    "# batch_size = 64\n",
    "# seq_len = 80\n",
    "# maximum_position_encoding = 256\n",
    "# rate = 0.1\n",
    "# num_heads = 2\n",
    "# num_layers = 4\n",
    "# z = RandomNoise_Simulator_Normal(batch_size, seq_len, features)\n",
    "\n",
    "# #Transformer Model\n",
    "# input_ = tf.keras.layers.Input(shape=(None, features))\n",
    "# x = InputEmbedLayer(features, dff , d_embedding)(input_)\n",
    "\n",
    "# pos_encoding = positional_encoding(maximum_position_encoding, d_embedding)   #(1, maximum_position_encoding=256, d_model=128)\n",
    "\n",
    "# seq_len = tf.shape(x)[1]\n",
    "# x += pos_encoding[:, :seq_len, :]     #x is the output of Input layer\n",
    "\n",
    "# x = tf.keras.layers.Dropout(rate)(x, training=True)\n",
    "\n",
    "# attention_weights = {}\n",
    "# mask, _ = create_masks(tar)\n",
    "# for i in range(num_layers):\n",
    "#     d_inp_decoder = tf.keras.backend.int_shape(x)[-1]\n",
    "#     x, attentionweights = DecoderLayer(d_inp_decoder, d_model, num_heads, dff)(x, True, mask)\n",
    "#     attention_weights['decoder_layer{}'.format(i+1)] = attentionweights\n",
    "\n",
    "# final_output = tf.keras.layers.Dense(d_model, activation=None)(x)\n",
    "\n",
    "\n",
    "# model = tf.keras.models.Model(input_, final_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mainenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
